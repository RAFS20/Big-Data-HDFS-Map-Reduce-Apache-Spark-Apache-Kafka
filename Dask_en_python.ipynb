{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAFS20/Big-Data-HDFS-Map-Reduce-Apache-Spark-Apache-Kafka/blob/main/Dask_en_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuaderno de: Ricardo Alonzo Fernández Salguero"
      ],
      "metadata": {
        "id": "0410tF3S5IoF"
      },
      "id": "0410tF3S5IoF"
    },
    {
      "cell_type": "markdown",
      "id": "1940f002",
      "metadata": {
        "id": "1940f002"
      },
      "source": [
        "# Ejemplos de Uso de Dask en Python\n",
        "\n",
        "## 1. Introducción a Dask\n",
        "\n",
        "### ¿Qué es Dask?\n",
        "\n",
        "Dask es una biblioteca de Python que permite el procesamiento paralelo y distribuido de datos de manera eficiente. Está diseñado para manejar conjuntos de datos que no caben en la memoria RAM de una sola máquina, así como para aprovechar al máximo los recursos de procesamiento disponibles en clústeres de computadoras. Dask proporciona abstracciones de alto nivel para trabajar con arreglos de datos (Dask Arrays), marcos de datos (Dask DataFrames) y flujos de datos (Dask Bags), que son análogos a los objetos de NumPy, Pandas y herramientas similares, pero optimizados para trabajar con grandes volúmenes de datos.\n",
        "\n",
        "### Ventajas de usar Dask sobre otras herramientas de procesamiento de datos\n",
        "\n",
        "#### 1. Escalabilidad:\n",
        "Dask permite escalar el procesamiento de datos desde una sola máquina hasta clústeres de computadoras, lo que permite manejar conjuntos de datos de cualquier tamaño sin sacrificar el rendimiento.\n",
        "\n",
        "#### 2. Paralelismo:\n",
        "Dask aprovecha el paralelismo de manera eficiente, dividiendo las tareas en pequeñas operaciones que pueden ejecutarse en paralelo en múltiples núcleos de CPU o nodos de un clúster.\n",
        "\n",
        "#### 3. Integración con el ecosistema de Python:\n",
        "Dask se integra fácilmente con otras bibliotecas y herramientas populares de Python, como NumPy, Pandas, Scikit-learn y TensorFlow, lo que permite aprovechar las funcionalidades existentes mientras se escalan para manejar grandes volúmenes de datos.\n",
        "\n",
        "Ahora vamos a explorar algunos ejemplos prácticos de cómo usar Dask en Python para diferentes tareas de procesamiento de datos.\n",
        "\n",
        "## 2. Creación y Manipulación de Datos con Dask\n",
        "\n",
        "### Ejemplo 1: Generación de Datos Masivos\n",
        "\n",
        "Para empezar, vamos a crear conjuntos de datos masivos simulados que utilizaremos en nuestros ejemplos. Utilizaremos la función `dask.array.random.normal` para generar arreglos de datos aleatorios con una distribución normal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bb687a69",
      "metadata": {
        "id": "bb687a69"
      },
      "outputs": [],
      "source": [
        "\n",
        "import dask.array as da\n",
        "\n",
        "# Crear un arreglo Dask con 10 millones de números aleatorios distribuidos normalmente\n",
        "datos_masivos = da.random.normal(size=(10000000,), chunks=(1000000,))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "985a23a5",
      "metadata": {
        "id": "985a23a5"
      },
      "source": [
        "\n",
        "\n",
        "Este código crea un arreglo Dask con 10 millones de números aleatorios distribuidos normalmente, divididos en bloques de un millón de elementos cada uno (chunks). Ahora que tenemos datos masivos generados, podemos utilizarlos para realizar diversas operaciones con Dask.\n",
        "\n",
        "### Ejemplo 2: Cálculo de Estadísticas Descriptivas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ce6ce1ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce6ce1ab",
        "outputId": "c6c19d8a-b500-46c5-b2fd-47f067ee90b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media: -0.00034505804252840037\n",
            "Desviación estándar: 0.9999000930609372\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular la media y la desviación estándar de los datos\n",
        "media = datos_masivos.mean()\n",
        "desviacion_estandar = datos_masivos.std()\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(\"Media:\", media.compute())\n",
        "print(\"Desviación estándar:\", desviacion_estandar.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc103ea",
      "metadata": {
        "id": "4cc103ea"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, calculamos la media y la desviación estándar de los datos masivos utilizando las funciones `mean()` y `std()` de Dask. La función `compute()` se utiliza para ejecutar las operaciones y obtener los resultados reales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0965efc",
      "metadata": {
        "id": "e0965efc"
      },
      "source": [
        "### Ejemplo 4: Operaciones de Álgebra Lineal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "98234c4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98234c4d",
        "outputId": "60b0b7a5-8de3-4ee2-bf07-ee04f193f15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Producto punto: -156.96249641322436\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular el producto punto entre dos arreglos de datos masivos\n",
        "datos_masivos_2 = da.random.normal(size=(10000000,), chunks=(1000000,))\n",
        "producto_punto = da.dot(datos_masivos, datos_masivos_2)\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(\"Producto punto:\", producto_punto.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cc93302",
      "metadata": {
        "id": "4cc93302"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, calculamos el producto punto entre dos arreglos de datos masivos utilizando la función `dot()` de Dask. Este tipo de operaciones de álgebra lineal se pueden realizar de manera eficiente incluso en conjuntos de datos masivos gracias al paralelismo que ofrece Dask.\n",
        "\n",
        "Estos ejemplos ilustran cómo podemos utilizar Dask para crear, manipular y realizar operaciones en conjuntos de datos masivos de manera eficiente y escalable. En los siguientes ejemplos, exploraremos técnicas avanzadas de procesamiento de datos con Dask, como el procesamiento distribuido y la optimización del rendimiento.\n",
        "\n",
        "\n",
        "# Ejemplos de Uso de Dask Arrays en Python\n",
        "\n",
        "## 1. Creación de Arrays Dask\n",
        "\n",
        "Dask Arrays proporciona una manera eficiente de trabajar con grandes conjuntos de datos multidimensionales, que no caben en la memoria RAM de una sola máquina. En este ejemplo, exploraremos diferentes métodos para crear y manipular arrays Dask.\n",
        "\n",
        "### Ejemplo 1: Creación de un Array Dask Aleatorio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a001bb3f",
      "metadata": {
        "id": "a001bb3f"
      },
      "outputs": [],
      "source": [
        "\n",
        "import dask.array as da\n",
        "\n",
        "# Crear un array Dask de 100 millones de elementos distribuidos normalmente\n",
        "datos_masivos = da.random.normal(size=(100000000,), chunks=(1000000,))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c3cf34",
      "metadata": {
        "id": "99c3cf34"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos la función `random.normal` de Dask Arrays para generar un array Dask con 100 millones de elementos distribuidos normalmente. Especificamos el tamaño del array y el tamaño de los chunks (bloques) en los que se dividirá el array para el procesamiento paralelo.\n",
        "\n",
        "### Ejemplo 2: Creación de un Array Dask a partir de Datos Existente\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "7c99326e",
      "metadata": {
        "id": "7c99326e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Crear un array NumPy de datos simulados\n",
        "datos_numpy = np.random.randint(0, 100, size=(1000, 1000))\n",
        "\n",
        "# Convertir el array NumPy en un array Dask\n",
        "array_dask = da.from_array(datos_numpy, chunks=(100, 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86008876",
      "metadata": {
        "id": "86008876"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un array NumPy con datos simulados y luego lo convertimos en un array Dask utilizando la función `from_array`. Especificamos el tamaño de los chunks para dividir el array en bloques para el procesamiento paralelo.\n",
        "\n",
        "## 2. Operaciones Básicas con Arrays Dask\n",
        "\n",
        "Una vez que hemos creado arrays Dask, podemos realizar una variedad de operaciones básicas, como cálculos matemáticos, indexación y manipulación de datos.\n",
        "\n",
        "### Ejemplo 3: Suma de Dos Arrays Dask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "544dd5ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "544dd5ca",
        "outputId": "1c2ce163-1157-49ef-b025-5e5ad0aca704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suma: [-0.25361616  0.5230344  -0.16795196 -0.32606019 -0.8207209   1.4003788\n",
            " -0.57105666  1.91703054 -0.27848684 -0.55675896]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Crear dos arrays Dask de datos simulados\n",
        "datos_a = da.random.normal(size=(1000000,), chunks=(100000,))\n",
        "datos_b = da.random.normal(size=(1000000,), chunks=(100000,))\n",
        "\n",
        "# Calcular la suma de los dos arrays\n",
        "suma = datos_a + datos_b\n",
        "\n",
        "# Imprimir los primeros 10 elementos de la suma\n",
        "print(\"Suma:\", suma[:10].compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fb20e40",
      "metadata": {
        "id": "6fb20e40"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos dos arrays Dask con datos simulados y luego calculamos la suma de los dos arrays utilizando el operador `+`. Utilizamos la función `compute()` para obtener los resultados reales.\n",
        "\n",
        "### Ejemplo 4: Indexación y Slicing de un Array Dask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4e22b23c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e22b23c",
        "outputId": "64bc42af-a4ee-4623-fe8e-1bab17e7a111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subconjunto de datos: [-3.91813427e-01  2.15705498e-02 -1.19924746e+00 -8.07129400e-01\n",
            " -7.63635912e-01 -1.09126858e+00  1.14121379e-01  3.49477694e-01\n",
            "  1.84976892e+00  1.13451795e-01  1.10914454e+00  7.40372916e-01\n",
            " -3.09966236e-02 -2.48689207e-01 -5.62575409e-02 -6.32299958e-01\n",
            " -8.25043139e-01 -1.61138731e+00  8.54981640e-01  1.29444745e+00\n",
            " -1.43680785e+00 -2.71259284e-02 -1.01920277e-01 -4.65958138e-01\n",
            " -7.17015123e-02 -1.41452399e-01  1.14378681e-02  6.94630357e-02\n",
            " -4.36793095e-03 -2.73170315e+00 -1.46017412e+00 -1.31245546e+00\n",
            "  1.15177200e+00  2.14609467e+00 -1.54744242e+00  1.60423622e-01\n",
            " -3.41711120e-01 -9.96263519e-03  1.02707926e+00 -8.27794648e-01\n",
            "  9.57379772e-01 -9.25331160e-01  3.80240190e-01 -1.32288219e-02\n",
            " -8.65907029e-02  1.08877324e+00 -4.04395564e-01 -1.05973832e+00\n",
            " -6.28195183e-02 -7.01887114e-01  1.74665512e+00  3.32528192e-01\n",
            " -1.15294272e+00 -5.67894903e-01  6.67690588e-01 -6.95606850e-01\n",
            " -1.33547238e+00 -1.90558582e+00 -2.13720043e+00  6.70584346e-01\n",
            " -6.11043984e-01  1.67237436e-01 -2.04246732e+00  8.69178904e-01\n",
            " -6.84603985e-01 -9.28572890e-01 -1.20761323e+00  1.66509302e-01\n",
            "  5.82792122e-01 -2.75641835e-01  1.96634719e+00 -2.84727011e-01\n",
            " -6.98227033e-01 -7.29809689e-01 -1.15625882e-01 -5.22280559e-01\n",
            " -4.96460057e-01  9.07584304e-01 -6.10575579e-01  1.04692608e+00\n",
            "  1.89864288e-01  1.50944383e+00 -1.68913690e-01 -3.59795417e+00\n",
            "  9.71299985e-01  2.83756620e-01  1.50054498e+00 -5.00301057e-01\n",
            " -8.15617823e-01 -4.56689440e-01 -3.66480384e-01 -1.08514386e+00\n",
            "  1.57156475e-01 -1.57270710e+00  5.78738400e-01  5.83448984e-01\n",
            "  1.09415226e+00  2.69859000e+00  1.39397478e+00 -2.63723264e+00\n",
            "  5.86618364e-02  5.29025576e-01  1.43530888e+00 -5.37532951e-01\n",
            " -3.42929537e-01 -3.65411943e-01  1.45890652e+00  2.21548683e-01\n",
            "  1.19443749e+00 -1.58102725e+00 -1.30397013e+00 -3.40467849e-01\n",
            " -1.76478639e-01  1.21935384e+00 -4.36440911e-01  2.12504772e+00\n",
            " -7.65224531e-01  1.03459171e+00  8.43076942e-02  2.32406266e-01\n",
            " -3.41803654e-01 -5.14310169e-01  4.13512418e-01 -4.56098488e-01\n",
            " -9.48394343e-01  7.28026434e-01 -1.38312504e-02  3.27743181e-01\n",
            " -1.19875044e+00 -1.26101189e+00  6.28904515e-01  9.58243535e-01\n",
            "  1.27196863e+00  6.34039968e-01  7.43846666e-01 -7.68465219e-01\n",
            "  4.96226177e-01 -1.30507911e-01 -1.23958371e+00  9.30484986e-01\n",
            "  4.84482417e-01  7.85706997e-03  5.82628614e-01 -7.87497003e-01\n",
            " -3.71953369e-02 -1.77454900e-01  2.78165005e+00  9.38827722e-02\n",
            "  4.31170416e-01  1.23922039e+00  3.68298359e-01 -1.50158586e+00\n",
            " -1.75425130e-01 -6.26932158e-01  2.01020281e+00  8.43724810e-01\n",
            "  8.15151489e-01  1.00349358e+00  6.25702816e-01  6.71663493e-02\n",
            " -2.30803430e-01  1.41669626e+00  2.31568750e-01 -8.59605478e-02\n",
            " -8.87439428e-01  4.69911820e-01 -5.68390338e-01  1.99337024e-02\n",
            " -6.53776021e-01 -1.38832919e+00 -1.39419104e-01  5.32784442e-01\n",
            " -3.58276557e-01 -2.22650137e-01  4.83169163e-01 -3.43376504e-01\n",
            " -1.59916968e+00  1.04081585e+00  4.32500891e-01  6.27239083e-01\n",
            " -8.99634531e-01  6.13004337e-01 -1.93276745e+00  1.21366593e-01\n",
            "  1.07599706e+00 -1.67532897e-01  1.27490799e+00  8.86895746e-01\n",
            "  1.26398091e-01 -9.16595894e-02 -1.78771280e+00 -1.61883771e+00\n",
            "  2.71113321e-01 -1.21413802e+00 -1.12756581e+00 -1.28781663e+00\n",
            " -2.17261124e-01  4.78971214e-01  4.30406346e-01 -1.20189404e+00\n",
            "  1.66957445e-01 -6.71569888e-01  9.19556168e-01  5.32993981e-01\n",
            "  6.56792395e-01  2.07161852e-01 -3.05885098e+00 -1.16687505e+00\n",
            " -1.13448217e-01 -6.97322190e-01 -2.71856517e+00 -2.31774817e-01\n",
            " -6.70210483e-02  1.07528282e-01  1.94888971e+00  3.18573337e-01\n",
            " -6.51054274e-01 -4.73396246e-01  5.11356140e-01  7.78868974e-01\n",
            "  7.72119176e-01 -6.33038307e-01  1.10933333e+00  2.52040460e-01\n",
            "  9.94684129e-01 -2.43172137e-01  7.44176447e-01 -9.07600834e-01\n",
            " -6.67232816e-01 -3.64466495e-02  6.91624377e-01 -5.41203473e-01\n",
            "  9.92254850e-01  6.04476339e-01 -4.56958042e-01 -1.95887578e-01\n",
            "  1.01711012e+00  7.73872012e-01 -1.02460397e+00 -6.60869158e-01\n",
            " -2.91367661e-01  6.38866078e-02  2.12378701e-01  1.42958869e+00\n",
            "  9.26161726e-01 -8.08540487e-01 -1.90379490e-01 -1.53244521e+00\n",
            " -7.23259884e-02 -7.59808587e-01  4.10347994e-01 -1.36286117e+00\n",
            " -1.25649123e+00 -1.25075001e+00  4.70368390e-01 -9.62296182e-01\n",
            " -1.38235338e-01  5.83583987e-01 -4.52852679e-01 -2.04964120e-01\n",
            " -6.43294598e-01 -1.13099981e+00  5.45091411e-01  1.23737825e+00\n",
            "  3.58877574e-01 -1.39962087e+00  7.48387506e-01  1.35749236e+00\n",
            " -2.62959041e-01 -6.67915058e-01  1.47836524e+00 -1.78446164e+00\n",
            "  1.04925222e+00 -8.82287720e-02 -5.91233852e-01  2.80682976e-01\n",
            " -2.83508741e+00 -1.05502562e+00  1.00381884e+00  1.41124741e+00\n",
            " -2.60561742e-01 -4.95072751e-02 -6.85094876e-02 -2.86806420e-01\n",
            " -2.32104832e+00  1.74867563e+00 -4.43936050e-01  6.49399984e-01\n",
            "  3.63743527e-01  8.76222116e-01 -2.07198901e+00 -1.54799316e-01\n",
            "  4.16011348e-01 -4.20083079e-01  8.70082289e-01 -4.98470320e-01\n",
            "  8.61856545e-01 -4.66759865e-01  2.35290145e+00  3.98669997e-02\n",
            "  3.51279510e-01 -1.94934779e+00  1.84553889e+00  1.69629508e-02\n",
            "  1.52460180e+00 -1.41181456e+00  2.26329718e+00 -2.95497534e-01\n",
            "  2.50785114e+00  4.10275539e-01  1.59944896e+00  8.00786119e-01\n",
            " -1.59166030e+00 -1.59078070e-01 -7.06379271e-01  1.74746008e+00\n",
            "  5.42712155e-01 -1.23738344e+00 -1.52171374e+00 -9.24513759e-01\n",
            "  6.33274850e-01  1.23906332e+00 -6.67632074e-01  2.05328525e-01\n",
            " -1.58830912e+00  8.92765626e-01  1.97462039e+00  9.40252676e-01\n",
            " -2.76265053e-01  2.91658877e-01 -8.36608572e-01 -9.26134381e-01\n",
            " -1.31550268e+00 -1.74449827e+00  8.28278295e-01  8.04800330e-01\n",
            "  1.11036620e+00  2.85673931e-01  1.64178972e+00 -1.50834220e-02\n",
            "  9.37302815e-02 -3.51281279e-01 -2.26627856e-01 -1.71347847e-01\n",
            "  9.79586795e-01  1.04164389e+00  6.68455741e-01  7.37056930e-01\n",
            "  4.32293535e-01  9.88367708e-01 -1.20193092e-01  4.01019598e-01\n",
            " -2.17220631e-01 -8.94457353e-01  1.20866144e+00 -6.80287908e-01\n",
            "  1.06478960e-01 -1.07471235e+00 -1.23618921e-02 -1.10569181e+00\n",
            " -3.31557897e-01 -1.08179180e+00 -6.37697123e-01 -1.08671072e+00\n",
            "  4.61554487e-01 -1.09637675e+00  5.14392154e-01 -1.02561825e+00\n",
            "  8.78675556e-03  1.65635762e+00  1.68476680e-02 -1.95226016e+00\n",
            " -1.21004069e+00 -9.15306441e-01 -9.32737324e-01  5.95885777e-01\n",
            " -1.57534630e-01  4.20687659e-01 -8.19340986e-01 -6.29105737e-01\n",
            "  7.04577892e-02  1.05064617e+00  5.97345696e-01 -1.44983778e+00\n",
            " -6.84438951e-01  2.50578243e+00  6.49176423e-01  1.96249368e+00\n",
            "  1.56300945e+00 -8.71527661e-01 -3.75645419e-01  1.15459762e+00\n",
            " -1.36944060e+00  4.61608616e-01 -2.07420270e-01 -1.44860088e-01\n",
            " -1.09197461e+00 -1.07723238e+00 -1.44384808e+00 -1.56097711e+00\n",
            "  3.26020465e-01  4.17170397e-01  6.09956835e-01  1.38831469e+00\n",
            " -8.20059997e-02  1.75063633e+00  3.97494578e-02 -1.47941336e+00\n",
            " -5.11645517e-01  1.39411852e+00 -1.97967086e+00 -6.38012778e-01\n",
            " -9.30912647e-01  1.01902071e-01 -9.05892746e-01 -1.46349342e-02\n",
            "  1.49045985e+00  8.07110607e-01  6.96925254e-01  1.57438490e-01\n",
            "  2.79212936e-01  1.07572173e-01 -1.00275751e-01  1.86958199e+00\n",
            " -4.04483298e-01  1.19177274e+00  3.03190846e-01  5.86652338e-01\n",
            "  3.92308349e-01 -9.49740060e-01  1.39854216e+00 -1.20258093e+00\n",
            "  1.22798204e+00  5.19228422e-01  1.29158426e+00  1.20512596e+00\n",
            " -1.12909661e+00 -1.22746960e+00 -3.25802681e-01 -8.22481670e-01\n",
            "  1.06781227e+00 -7.88083187e-01 -4.53454429e-01 -9.19802892e-01\n",
            " -1.66837775e+00 -1.28286145e+00  8.24576345e-01  6.44289329e-02\n",
            " -1.43201461e+00  6.56148086e-01 -4.08722340e-01  1.37159904e+00\n",
            " -7.93324705e-01 -3.02472454e+00  7.33887792e-01 -5.51399906e-01\n",
            "  1.21273778e+00 -7.23269619e-01 -1.48501142e+00 -9.26764352e-02\n",
            "  1.52707445e+00  5.54858705e-01 -4.95198975e-01 -1.58799788e-01\n",
            " -1.45092050e+00 -2.49873053e-01 -1.28288057e+00  5.11007571e-01\n",
            " -1.34450620e-02  1.44865318e+00 -1.12969010e-01 -7.54384148e-01\n",
            "  6.19251008e-01  5.37792705e-01  6.72490490e-01  1.31953931e+00\n",
            " -7.73235822e-01 -1.22025239e+00  7.30794409e-01 -1.12727665e-01\n",
            " -6.31817551e-01  2.20975300e-01 -1.70128174e+00 -3.60864807e-01\n",
            " -1.09850449e+00  1.49527042e+00 -5.10628962e-02 -4.12823046e-01\n",
            "  7.45518523e-02 -2.42576341e-01  9.22345735e-01  8.85179497e-01\n",
            " -3.22813281e-01 -3.09689514e-01 -6.14281632e-02  6.52645360e-01\n",
            "  1.23600975e-01  2.37257326e+00 -1.21849459e+00  1.91604196e+00\n",
            "  7.11666159e-02  6.59473630e-01  1.56581844e+00 -1.41129565e-01\n",
            "  4.17681010e-01 -2.64512040e+00  8.35405548e-01 -1.32367213e+00\n",
            "  1.05201448e+00 -7.82842593e-02 -8.99926511e-01  8.60330209e-01\n",
            "  1.77588007e+00 -1.23241442e+00  9.41992943e-01 -4.51003625e-01\n",
            " -1.19722647e+00 -1.45092006e+00  1.66499567e+00 -1.13398174e+00\n",
            " -1.17954551e-01  1.12433016e+00 -1.54370641e-01 -3.53620144e-01\n",
            "  7.84729979e-01 -1.18760547e+00  1.33266230e+00  1.45660359e+00\n",
            " -1.34130218e+00  5.35901801e-01 -1.02151622e+00  6.76291148e-01\n",
            " -9.85289363e-01 -1.03115990e+00  8.48174799e-01 -1.24114220e+00\n",
            "  4.31257161e-01 -3.35323475e-01 -2.81088699e-01 -1.03304181e+00\n",
            " -2.42675163e-01  1.40926404e+00  2.02752033e+00  1.17615776e+00\n",
            " -1.26068837e+00 -3.33535662e-01  3.50377485e-01 -4.02612572e-01\n",
            " -1.18192415e+00  2.47057810e-01  1.89349334e+00  2.75068807e-01\n",
            " -6.39467712e-01  1.95713332e+00 -5.72944859e-01  9.26980548e-01\n",
            " -1.88347135e+00  1.04438227e+00  3.57673819e-02 -9.04043112e-02\n",
            " -7.83822842e-01  2.98900456e-01  2.47173189e+00 -2.16198846e-01\n",
            " -8.47247368e-01  1.05588555e+00 -1.13103397e+00 -1.04776795e+00\n",
            "  2.99910244e-01 -6.56708216e-01 -3.63887703e-03 -2.33817530e-01\n",
            "  5.17167174e-01  6.27774730e-01  3.07878349e-03 -2.50162278e-01\n",
            "  1.27496480e+00 -1.27549256e+00  4.43154116e-01  6.34735521e-01\n",
            "  5.31397308e-02 -2.59692326e-01  1.14778415e+00 -4.17697436e-01\n",
            " -3.55505799e-01  5.97861900e-01 -2.73440084e-01  1.24069998e+00\n",
            "  4.15043159e-01 -1.15569046e-01  2.71050034e-01  8.57226431e-01\n",
            "  9.71162840e-01 -9.20160420e-01 -6.63476562e-02 -2.47780895e-01\n",
            " -3.62267608e-01 -1.80230030e+00  1.17407963e+00 -1.25197614e+00\n",
            " -9.31912668e-02  1.68822204e+00 -5.28282033e-02 -1.37956543e+00\n",
            " -1.70163176e-01 -7.75444900e-02 -3.98449133e-01  4.09970034e-01\n",
            " -8.34660240e-01  2.88742435e-01  7.83638421e-01 -7.77857191e-01\n",
            " -2.13281391e-01 -1.79081831e+00 -1.05225815e-03 -2.68737035e-01\n",
            " -3.02088833e-01 -3.97237379e-01 -6.53508252e-01  1.38550894e+00\n",
            "  1.04084691e-02 -2.84849380e-01 -1.85965420e+00  5.63776943e-01\n",
            "  3.07250677e-01  1.80951876e+00  1.23621834e+00 -3.05393864e-01\n",
            "  1.41877183e+00 -4.19042583e-01 -8.21151268e-01 -5.62611093e-01\n",
            " -2.05697783e-01  3.44742966e-01 -5.22795720e-01 -1.10925397e+00\n",
            "  3.90454195e-01 -1.48911160e+00  6.69274228e-01 -1.80852614e-01\n",
            " -1.19703180e+00 -3.84042340e-01  8.08379992e-01 -4.12027908e-01\n",
            "  3.22990220e-01  4.71922810e-01  4.29136478e-01  1.20013685e+00\n",
            "  4.08834234e-01  1.02584141e+00  1.84037914e+00 -1.33051813e+00\n",
            " -1.90160332e+00  9.84016320e-02 -3.58651327e-01 -6.08500945e-01\n",
            " -1.32213742e+00  4.30236147e-01 -1.22966055e+00  2.17295826e-01\n",
            "  2.54262068e-01  1.18403307e+00 -1.46076311e-01 -6.51466177e-01\n",
            "  1.14010185e+00  7.13976793e-02 -3.89132003e-01 -1.06403940e+00\n",
            " -4.64099067e-01  4.65034236e-02  2.25454047e+00  7.72163774e-01\n",
            " -6.16225289e-01  1.64353497e+00  3.98318528e-01 -1.50261240e+00\n",
            "  3.02103356e-01  5.80435973e-01  6.90876389e-02 -2.96652940e-01\n",
            "  8.53857554e-01 -3.94104166e-02  5.40577493e-01 -1.49923769e+00\n",
            " -8.11660712e-02  1.25384615e+00 -6.71594053e-01 -9.89700890e-01\n",
            "  1.87255710e+00  1.22307969e+00 -1.72551095e+00 -8.39743697e-01\n",
            " -1.73519551e+00 -7.47827445e-01 -5.07843466e-01 -2.82315567e-01\n",
            " -5.52502147e-01 -7.21819500e-01 -1.02864814e+00  5.39183007e-01\n",
            "  6.47016281e-01 -1.93709536e-01 -3.04459644e+00 -4.62445090e-01\n",
            "  2.49610658e-01 -5.17129655e-01  1.13210882e+00  2.33191783e-01\n",
            "  9.10929633e-01  3.47699035e-01 -3.45869004e-01  8.66078060e-01\n",
            "  1.54780332e+00 -1.38947342e+00  4.06319322e-01  2.51313733e-01\n",
            " -2.98229029e-01 -1.33324232e-01  1.06847213e-01  2.34668571e-01\n",
            "  5.54707021e-01  1.49339733e+00 -1.97648211e+00  1.53609661e+00\n",
            " -1.61624972e+00  3.13577726e-01  1.28137895e+00 -7.25025878e-02\n",
            "  6.14529621e-01 -7.21536691e-01 -8.79221634e-01  3.51881360e-01\n",
            " -1.56112399e+00  1.36568967e-01  1.67012808e-01 -1.65358699e+00\n",
            " -4.45919751e-01 -1.40061044e+00 -1.43207121e+00  7.66265491e-01\n",
            "  4.27107846e-01 -3.83641022e-01 -5.83958170e-01 -8.18334634e-01\n",
            " -4.68926051e-01  6.29233650e-01  1.17782647e+00 -3.28083426e-01\n",
            " -1.18675199e-02 -3.83699790e-01  1.53026409e-01  6.98288066e-01\n",
            " -6.40090607e-01  9.09592436e-01  2.77116143e-01  1.12296298e+00\n",
            "  1.32383411e-01  9.34999343e-01  4.56945939e-01  1.80182921e+00\n",
            "  9.19752256e-02 -9.44774400e-01  1.37440139e+00  1.03704246e+00\n",
            " -3.80293833e-01  9.52897042e-01  2.90143569e-01 -1.52103439e-01\n",
            "  5.95093543e-01  4.66077194e-02  1.83853492e-01 -4.15725277e-01\n",
            "  1.13064630e-02 -4.46909726e-01 -5.55684589e-02  2.28835089e-01\n",
            "  6.30394729e-01  7.98966980e-02 -1.63218102e+00 -7.99575844e-01\n",
            " -2.09787994e-01  6.42415381e-01 -1.42367023e-01 -9.65637688e-01\n",
            "  1.69048661e+00 -2.32412064e+00 -4.44115851e-01 -1.80269881e+00\n",
            " -3.75242050e-01 -7.13021524e-01  9.87652702e-01 -1.89330396e+00\n",
            "  1.11403205e+00 -1.09044045e+00  2.87009740e-01  2.71488306e+00\n",
            " -8.53907223e-01  1.82234640e+00 -3.45502611e-01  1.33226311e+00\n",
            "  4.93884593e-01 -2.45508714e-01  2.17675972e+00  1.43208796e+00\n",
            "  8.43427910e-01 -1.41313628e-01 -1.01081186e-01 -1.52726242e+00\n",
            " -6.02452551e-01  1.72905566e+00 -1.59529400e+00 -3.23600016e-01\n",
            " -2.94849754e-01  1.35172718e-01 -3.29756599e-01  9.52006022e-01\n",
            "  7.64059966e-01  2.40579560e-01  1.76801179e-01  1.71973389e+00\n",
            "  1.15303931e+00 -4.89957310e-01 -2.50678894e+00 -1.54073542e+00\n",
            " -3.27869322e-01  4.54779329e-01  1.76219811e-01 -1.26348666e+00\n",
            "  3.88954449e-01  3.30999891e-01  9.47570545e-01  1.68908499e+00\n",
            "  1.95802817e+00 -2.50720812e-01 -4.43182111e-01 -1.41081400e+00\n",
            "  3.18181323e+00  5.31742649e-01  1.56498795e+00  4.48740067e-02\n",
            " -1.42045456e-01 -1.66740540e-01 -4.42688497e-01  9.88804929e-02\n",
            "  7.92615619e-01  1.59613785e+00  1.49542431e+00 -7.98637473e-01\n",
            " -1.53134772e+00 -1.36562135e-01  8.61736460e-01 -2.03899228e+00\n",
            "  5.04184671e-01 -6.43357454e-01 -2.10378013e+00 -1.07680002e+00\n",
            " -2.00037006e+00 -1.25282388e+00  1.01260815e+00 -1.11319835e+00\n",
            " -9.36559078e-02  4.70431647e-01 -8.97745275e-01 -1.32886818e+00\n",
            " -1.19743243e+00 -1.19153495e+00 -1.13035125e+00  1.93517538e+00\n",
            "  1.58186562e+00  1.89338537e-03  8.03018841e-01 -2.38163814e-01\n",
            "  9.25060980e-02  1.02030197e+00 -5.70267890e-01  1.98515401e+00\n",
            " -6.36432817e-01  9.92817576e-01  7.98776393e-01  2.05817126e-01\n",
            "  1.39717236e+00  1.78686809e+00 -4.78289740e-01  6.38592023e-01\n",
            "  1.67482454e+00 -2.59223498e-01  1.37643831e+00  9.22146904e-01\n",
            "  9.45053785e-01  1.32376326e+00 -1.13217402e+00  5.25705159e-01\n",
            "  5.04704922e-01  1.19060468e+00  4.59030340e-01 -7.20555244e-01\n",
            " -9.61029907e-01  1.08272599e+00 -1.16459795e+00 -2.44053866e+00\n",
            " -2.34891241e-01  9.83672241e-01 -1.06802006e+00 -7.98527630e-01\n",
            "  1.01353592e+00 -1.50494260e+00  2.93307230e-01 -2.84782325e-01\n",
            "  4.41819463e-01  9.84755963e-01  2.93989848e-01 -6.55828741e-02\n",
            "  3.11117235e-01  4.72095152e-02  9.13399356e-02 -7.16279618e-01\n",
            "  8.15483052e-01 -6.46870791e-01  2.26896783e-01 -8.12452048e-01\n",
            "  2.67894881e-01  1.38836210e+00 -9.17565718e-01  1.39707350e-01\n",
            "  1.96472986e-01  2.33209516e-01 -3.05178473e-01 -7.52954933e-01\n",
            " -2.19159830e-01 -6.21264091e-01 -1.52007169e+00 -1.26318473e-02\n",
            "  4.64629260e-02 -2.02763087e-01 -8.38452556e-01 -1.13593734e-01\n",
            " -5.01313584e-01  1.98274888e-01  8.77183601e-02  1.12716724e+00\n",
            "  2.39157885e+00 -7.94372153e-02  1.22007166e+00 -7.44440311e-01\n",
            "  8.05894205e-02 -1.59103563e+00  6.59271100e-01  5.68670013e-01\n",
            "  1.16216534e+00  1.39660307e+00 -4.68705356e-01 -1.91602830e+00\n",
            "  1.16542061e+00  5.66926518e-01 -3.40277818e-01 -1.64468027e+00\n",
            "  1.92761400e+00 -1.01397869e-01 -1.74865559e-01 -2.18392905e-01\n",
            " -1.12661073e+00  3.62216970e-01 -6.45586368e-01 -8.88542675e-02\n",
            " -3.25488958e-01  5.30344157e-01  8.65116774e-02 -6.22394867e-02\n",
            "  1.90098967e+00  1.20377314e+00  2.70677793e-02  1.37886640e+00\n",
            "  2.47762510e-01  1.30175168e+00 -3.75067862e-01  1.51633174e+00\n",
            " -6.06575256e-01  3.82650497e-01 -1.46641942e+00  8.54644631e-01\n",
            " -2.46873008e+00 -1.48954440e+00 -8.60314861e-01  8.14235202e-02\n",
            " -1.48653039e-01 -8.86190660e-01  1.04603318e+00  1.13815768e+00\n",
            " -1.26905335e-01 -8.39204754e-02 -9.25209085e-01  6.81959272e-01\n",
            " -9.72573610e-01  4.99938633e-01  1.16271519e+00  4.03253169e-01\n",
            "  1.19681491e+00  3.18376635e-01 -1.08532873e+00 -9.87196179e-01]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Seleccionar un subconjunto de datos de un array Dask\n",
        "subconjunto = datos_masivos[50000000:50001000]\n",
        "\n",
        "# Imprimir el subconjunto de datos\n",
        "print(\"Subconjunto de datos:\", subconjunto.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdef6144",
      "metadata": {
        "id": "cdef6144"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, seleccionamos un subconjunto de datos de un array Dask utilizando la indexación y el slicing de la misma manera que lo haríamos con un array NumPy. Utilizamos la función `compute()` para obtener los resultados reales.\n",
        "\n",
        "### Ejemplo 5: Aplicación de Funciones Matemáticas a un Array Dask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e9dfb7d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9dfb7d1",
        "outputId": "a28c5a3a-d555-4a22-e639-46ff1c59b0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raíz cuadrada: [       nan 0.51826727        nan 0.24776559 0.79715713        nan\n",
            "        nan        nan        nan 1.16744345]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/core.py:121: RuntimeWarning: invalid value encountered in sqrt\n",
            "  return func(*(_execute_task(a, cache) for a in args))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular la raíz cuadrada de cada elemento del array\n",
        "raiz_cuadrada = da.sqrt(datos_masivos)\n",
        "\n",
        "# Imprimir los primeros 10 elementos de la raíz cuadrada\n",
        "print(\"Raíz cuadrada:\", raiz_cuadrada[:10].compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5079f82",
      "metadata": {
        "id": "f5079f82"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, aplicamos la función `sqrt` de NumPy a cada elemento del array Dask para calcular la raíz cuadrada. Nuevamente, utilizamos la función `compute()` para obtener los resultados reales.\n",
        "\n",
        "### Ejemplo 6: Reducción de Dimensionalidad\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "996a35ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "996a35ae",
        "outputId": "d9362340-c724-4988-f85e-7071a485a3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suma total: 16485.500835470375\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular la suma de todos los elementos del array\n",
        "suma_total = datos_masivos.sum()\n",
        "\n",
        "# Imprimir la suma total\n",
        "print(\"Suma total:\", suma_total.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d780c6",
      "metadata": {
        "id": "72d780c6"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos la función `sum()` de Dask para calcular la suma de todos los elementos del array Dask, reduciendo la dimensionalidad del array a un solo valor.\n",
        "\n",
        "Estos ejemplos ilustran algunas de las operaciones básicas que se pueden realizar con arrays Dask en Python. En los siguientes ejemplos, exploraremos operaciones más avanzadas y técnicas de optimización para mejorar el rendimiento del procesamiento de datos con Dask Arrays.\n",
        "\n",
        "\n",
        "# Ejemplos de Paralelismo y Distribución de Datos en Arrays Dask\n",
        "\n",
        "En este apartado, exploraremos cómo Dask aprovecha el paralelismo y distribuye los datos para mejorar el rendimiento en el procesamiento de arrays Dask.\n",
        "\n",
        "## 1. Paralelismo en Operaciones con Arrays Dask\n",
        "\n",
        "Una de las principales ventajas de Dask es su capacidad para ejecutar operaciones en paralelo, aprovechando al máximo los recursos disponibles, como múltiples núcleos de CPU o nodos de un clúster. A continuación, veremos algunos ejemplos de cómo se implementa el paralelismo en Dask.\n",
        "\n",
        "### Ejemplo 1: Suma de Dos Arrays en Paralelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ce075a71",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce075a71",
        "outputId": "b7023649-4463-4f59-a80b-4e40cdaa8fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suma: [0.3904735  0.72764006 0.49290446 1.69593966 1.54785205 1.05811112\n",
            " 0.76949988 0.56754174 0.71286501 0.38407733]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import dask.array as da\n",
        "\n",
        "# Crear dos arrays Dask de datos simulados\n",
        "datos_a = da.random.random(size=(1000000,), chunks=(100000,))\n",
        "datos_b = da.random.random(size=(1000000,), chunks=(100000,))\n",
        "\n",
        "# Calcular la suma de los dos arrays en paralelo\n",
        "suma = datos_a + datos_b\n",
        "\n",
        "# Imprimir los primeros 10 elementos de la suma\n",
        "print(\"Suma:\", suma[:10].compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4da4615c",
      "metadata": {
        "id": "4da4615c"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos dos arrays Dask con datos simulados y luego calculamos la suma de los dos arrays utilizando el operador `+`. Dask divide automáticamente los cálculos en pequeñas tareas que se pueden ejecutar en paralelo en múltiples núcleos de CPU.\n",
        "\n",
        "### Ejemplo 2: Aplicación de Función en Paralelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "870916a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "870916a9",
        "outputId": "35496627-20e8-4e59-ed43-445806b4d16a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raíz cuadrada: [0.52124234 0.29416939 0.44353434 0.90276728 0.79920121 0.8927423\n",
            " 0.42107368 0.69241883 0.72565357 0.22988124]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular la raíz cuadrada de cada elemento del array en paralelo\n",
        "raiz_cuadrada = da.sqrt(datos_a)\n",
        "\n",
        "# Imprimir los primeros 10 elementos de la raíz cuadrada\n",
        "print(\"Raíz cuadrada:\", raiz_cuadrada[:10].compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45e1418",
      "metadata": {
        "id": "e45e1418"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, aplicamos la función `sqrt` de NumPy a cada elemento del array Dask para calcular la raíz cuadrada. Dask distribuye automáticamente la operación en paralelo en los bloques de datos, lo que resulta en un procesamiento más rápido.\n",
        "\n",
        "## 2. Distribución de Datos en Arrays Dask\n",
        "\n",
        "Dask distribuye los datos en bloques (chunks) para facilitar el procesamiento paralelo y la gestión eficiente de la memoria. A continuación, veremos cómo podemos controlar la distribución de datos en los arrays Dask.\n",
        "\n",
        "### Ejemplo 3: Especificación de Tamaño de Chunks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3e3511a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e3511a9",
        "outputId": "3eac7dcc-1e81-4ccc-adf9-a1ff0f182c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de chunks: (10,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Crear un array Dask con datos simulados y especificar el tamaño de los chunks\n",
        "datos_distribuidos = da.random.random(size=(1000000,), chunks=(100000,))\n",
        "\n",
        "# Imprimir el número de chunks en el array\n",
        "print(\"Número de chunks:\", datos_distribuidos.numblocks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c090da59",
      "metadata": {
        "id": "c090da59"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un array Dask con datos simulados y especificamos el tamaño de los chunks utilizando el parámetro `chunks`. Esto divide el array en bloques de 100,000 elementos cada uno, lo que facilita el procesamiento paralelo y la gestión de la memoria.\n",
        "\n",
        "### Ejemplo 4: Reorganización de Chunks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ee92b7a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee92b7a6",
        "outputId": "d613d78b-9a83-45b7-f5a2-2657820b5237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de chunks (reorganizado): (20,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Reorganizar los chunks de un array Dask\n",
        "datos_reorganizados = datos_distribuidos.rechunk((50000,))\n",
        "\n",
        "# Imprimir el número de chunks en el array reorganizado\n",
        "print(\"Número de chunks (reorganizado):\", datos_reorganizados.numblocks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd906c5",
      "metadata": {
        "id": "9bd906c5"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, reorganizamos los chunks de un array Dask utilizando el método `rechunk`. Esto puede ser útil para optimizar el rendimiento de las operaciones, especialmente cuando se necesitan tamaños de chunks diferentes.\n",
        "\n",
        "Dask aprovecha el paralelismo y distribuye los datos de manera eficiente para mejorar el rendimiento en el procesamiento de arrays Dask. Esto permite manejar conjuntos de datos masivos que no caben en la memoria RAM de una sola máquina y realizar operaciones en paralelo para acelerar el procesamiento. Con los ejemplos proporcionados, hemos visto cómo podemos utilizar Dask para realizar operaciones en paralelo y controlar la distribución de datos en los arrays Dask para optimizar el rendimiento de nuestras aplicaciones.\n",
        "\n",
        "\n",
        "# Ejemplos de Uso de Dask DataFrames en Python\n",
        "\n",
        "En este apartado, exploraremos cómo trabajar con DataFrames Dask en Python para el procesamiento eficiente de grandes conjuntos de datos. Comenzaremos creando y cargando DataFrames Dask a partir de conjuntos de datos simulados.\n",
        "\n",
        "## 1. Creación y Carga de DataFrames Dask\n",
        "\n",
        "Antes de comenzar con los ejemplos, primero crearemos dos conjuntos de datos simulados y los guardaremos en archivos CSV. Luego, cargaremos estos archivos CSV en DataFrames Dask para su posterior procesamiento.\n",
        "\n",
        "### Creación y Guardado de Conjuntos de Datos Simulados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f4ae02eb",
      "metadata": {
        "id": "f4ae02eb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Crear primer conjunto de datos simulados\n",
        "datos_1 = pd.DataFrame({\n",
        "    'ID': range(1, 1000001),\n",
        "    'Nombre': ['Usuario_' + str(i) for i in range(1, 1000001)],\n",
        "    'Edad': [20 + i % 30 for i in range(1, 1000001)],\n",
        "    'Puntuación': [i % 100 for i in range(1, 1000001)]\n",
        "})\n",
        "\n",
        "# Guardar el primer conjunto de datos en un archivo CSV\n",
        "datos_1.to_csv('datos_1.csv', index=False)\n",
        "\n",
        "# Crear segundo conjunto de datos simulados\n",
        "datos_2 = pd.DataFrame({\n",
        "    'ID': range(1000001, 2000001),\n",
        "    'Nombre': ['Usuario_' + str(i) for i in range(1000001, 2000001)],\n",
        "    'Edad': [25 + i % 35 for i in range(1, 1000001)],\n",
        "    'Puntuación': [i % 75 for i in range(1, 1000001)]\n",
        "})\n",
        "\n",
        "# Guardar el segundo conjunto de datos en un archivo CSV\n",
        "datos_2.to_csv('datos_2.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b7380a",
      "metadata": {
        "id": "17b7380a"
      },
      "source": [
        "\n",
        "\n",
        "En este código, creamos dos conjuntos de datos simulados utilizando la biblioteca Pandas y los guardamos en archivos CSV llamados `datos_1.csv` y `datos_2.csv`.\n",
        "\n",
        "### Carga de Conjuntos de Datos en DataFrames Dask\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dc8a081c",
      "metadata": {
        "id": "dc8a081c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cargar los conjuntos de datos CSV en DataFrames Dask\n",
        "df_dask_1 = dd.read_csv('datos_1.csv')\n",
        "df_dask_2 = dd.read_csv('datos_2.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a0f54f",
      "metadata": {
        "id": "31a0f54f"
      },
      "source": [
        "\n",
        "\n",
        "En este código, cargamos los conjuntos de datos CSV en DataFrames Dask utilizando la función `read_csv` de Dask DataFrame.\n",
        "\n",
        "Ahora que hemos creado y cargado los conjuntos de datos, podemos comenzar a realizar operaciones básicas y manipulación de datos con DataFrames Dask.\n",
        "\n",
        "## 2. Operaciones Básicas con DataFrames Dask\n",
        "\n",
        "### Ejemplo 1: Concatenación de DataFrames\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7208f0d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7208f0d3",
        "outputId": "b7e88da4-487c-45ce-a3da-a6b4df7b2cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID     Nombre  Edad  Puntuación\n",
            "0   1  Usuario_1    21           1\n",
            "1   2  Usuario_2    22           2\n",
            "2   3  Usuario_3    23           3\n",
            "3   4  Usuario_4    24           4\n",
            "4   5  Usuario_5    25           5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Concatenar los dos DataFrames Dask\n",
        "df_concatenado = dd.concat([df_dask_1, df_dask_2])\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame concatenado\n",
        "print(df_concatenado.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9072306",
      "metadata": {
        "id": "c9072306"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos la función `concat` de Dask para concatenar los dos DataFrames Dask cargados previamente en uno solo.\n",
        "\n",
        "### Ejemplo 2: Filtrado de Datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "186fae60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "186fae60",
        "outputId": "5f5cb8cd-b5ae-494d-c85d-f185ea76a24b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ID      Nombre  Edad  Puntuación\n",
            "50  51  Usuario_51    41          51\n",
            "51  52  Usuario_52    42          52\n",
            "52  53  Usuario_53    43          53\n",
            "53  54  Usuario_54    44          54\n",
            "54  55  Usuario_55    45          55\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Filtrar los datos para mantener solo los usuarios con una puntuación mayor a 50\n",
        "df_filtrado = df_concatenado[df_concatenado['Puntuación'] > 50]\n",
        "\n",
        "# Imprimir las primeras filas del DataFrame filtrado\n",
        "print(df_filtrado.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40437c3c",
      "metadata": {
        "id": "40437c3c"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, filtramos los datos para mantener solo las filas donde la puntuación es mayor a 50.\n",
        "\n",
        "## 3. Manipulación de Datos con DataFrames Dask\n",
        "\n",
        "### Ejemplo 3: Agrupación y Cálculo de Estadísticas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ec39178c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec39178c",
        "outputId": "e91905c2-4242-43ac-9819-8cc677d0773c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Puntuación\n",
            "0     35.714224\n",
            "1     36.713337\n",
            "2     37.713337\n",
            "3     38.713337\n",
            "4     39.713337\n",
            "        ...    \n",
            "95    34.999000\n",
            "96    35.999000\n",
            "97    36.999000\n",
            "98    37.999000\n",
            "99    38.999000\n",
            "Name: Edad, Length: 100, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular la media de la edad por puntuación\n",
        "media_edad_por_puntuacion = df_concatenado.groupby('Puntuación')['Edad'].mean().compute()\n",
        "\n",
        "# Imprimir la media de la edad por puntuación\n",
        "print(media_edad_por_puntuacion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceca21e1",
      "metadata": {
        "id": "ceca21e1"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, agrupamos los datos por puntuación y calculamos la media de la edad para cada grupo.\n",
        "\n",
        "### Ejemplo 4: Agregación de Datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "16a5fb33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16a5fb33",
        "outputId": "92f5c3b7-6dda-40c6-a44b-c59080ddfe8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Puntuación\n",
            "0     23333\n",
            "1     23334\n",
            "2     23334\n",
            "3     23334\n",
            "4     23334\n",
            "      ...  \n",
            "95    10000\n",
            "96    10000\n",
            "97    10000\n",
            "98    10000\n",
            "99    10000\n",
            "Length: 100, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular el recuento de usuarios por puntuación\n",
        "recuento_por_puntuacion = df_concatenado.groupby('Puntuación').size().compute()\n",
        "\n",
        "# Imprimir el recuento de usuarios por puntuación\n",
        "print(recuento_por_puntuacion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae1249d",
      "metadata": {
        "id": "aae1249d"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, agregamos los datos por puntuación y calculamos el recuento de usuarios para cada grupo.\n",
        "\n",
        "Hemos visto cómo crear, cargar y manipular DataFrames Dask en Python para el procesamiento eficiente de grandes conjuntos de datos. Utilizando ejemplos con conjuntos de datos simulados, exploramos diversas operaciones básicas, como la concatenación, el filtrado, la agrupación y la agregación de datos. Dask proporciona una interfaz familiar de Pandas y puede escalar para manejar conjuntos de datos masivos que no caben en la memoria RAM de una sola máquina. Con los ejemplos proporcionados, esperamos haber demostrado la utilidad y la versatilidad de Dask para el procesamiento de datos a gran escala.\n",
        "\n",
        "\n",
        "# Ejemplos de Uso de Dask Bags en Python\n",
        "\n",
        "En este apartado, exploraremos cómo trabajar con Dask Bags en Python para realizar operaciones en conjuntos de datos no estructurados. Comenzaremos creando datos simulados y luego aplicaremos diversas operaciones utilizando Dask Bags.\n",
        "\n",
        "## 1. Creación de Datos Simulados\n",
        "\n",
        "Antes de comenzar con los ejemplos, crearemos datos simulados que utilizaremos para ilustrar las operaciones con Dask Bags. Vamos a simular datos de registros de ventas, donde cada registro tiene un ID de producto, una cantidad vendida y un precio unitario.\n",
        "\n",
        "### Creación de Datos Simulados\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "001ace50",
      "metadata": {
        "id": "001ace50"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "\n",
        "# Función para generar registros de ventas simulados\n",
        "def generar_registro_venta():\n",
        "    producto = random.choice(['Producto A', 'Producto B', 'Producto C'])\n",
        "    cantidad = random.randint(1, 10)\n",
        "    precio_unitario = round(random.uniform(10, 100), 2)\n",
        "    return {'producto': producto, 'cantidad': cantidad, 'precio_unitario': precio_unitario}\n",
        "\n",
        "# Generar una lista de 1 millón de registros de ventas simulados\n",
        "registros_ventas = [generar_registro_venta() for _ in range(1000000)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98f5255b",
      "metadata": {
        "id": "98f5255b"
      },
      "source": [
        "\n",
        "\n",
        "En este código, creamos una función `generar_registro_venta()` que genera un registro de venta simulado y luego utilizamos esta función para generar una lista de 1 millón de registros de ventas simulados.\n",
        "\n",
        "## 2. Creación y Uso de Dask Bags\n",
        "\n",
        "Ahora que tenemos datos simulados, podemos utilizar Dask Bags para procesarlos de manera eficiente.\n",
        "\n",
        "### Ejemplo 1: Creación de un Dask Bag\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "443f54d5",
      "metadata": {
        "id": "443f54d5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import dask.bag as db\n",
        "\n",
        "# Crear un Dask Bag a partir de la lista de registros de ventas simulados\n",
        "bag_ventas = db.from_sequence(registros_ventas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "621f8295",
      "metadata": {
        "id": "621f8295"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un Dask Bag a partir de la lista de registros de ventas simulados utilizando la función `from_sequence()` de Dask Bag.\n",
        "\n",
        "### Ejemplo 2: Filtrado de Datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b17c432b",
      "metadata": {
        "id": "b17c432b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Filtrar los registros de ventas para mantener solo los registros del Producto A\n",
        "ventas_producto_a = bag_ventas.filter(lambda x: x['producto'] == 'Producto A')\n",
        "\n",
        "# Contar el número de registros del Producto A\n",
        "num_ventas_producto_a = ventas_producto_a.count().compute()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fa05418",
      "metadata": {
        "id": "1fa05418"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, filtramos los registros de ventas para mantener solo los registros del Producto A utilizando el método `filter()` de Dask Bag y luego contamos el número de registros utilizando el método `count()`.\n",
        "\n",
        "### Ejemplo 3: Transformación de Datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "de4bab33",
      "metadata": {
        "id": "de4bab33"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calcular el total de ventas por producto\n",
        "ventas_por_producto = bag_ventas.map(lambda x: (x['producto'], x['cantidad'] * x['precio_unitario'])) \\\n",
        "                                 .frequencies()\n",
        "\n",
        "# Obtener los resultados como un diccionario\n",
        "resultados_ventas_por_producto = dict(ventas_por_producto.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e638d235",
      "metadata": {
        "id": "e638d235"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, calculamos el total de ventas por producto multiplicando la cantidad vendida por el precio unitario para cada registro de venta y luego contamos la frecuencia de cada producto utilizando el método `frequencies()`.\n",
        "\n",
        "### Ejemplo 4: Análisis de Datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b92aa9ad",
      "metadata": {
        "id": "b92aa9ad"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calcular el promedio de precio unitario de todos los productos\n",
        "promedio_precio_unitario = bag_ventas.pluck('precio_unitario').mean().compute()\n",
        "\n",
        "# Calcular la cantidad total de productos vendidos\n",
        "total_cantidad_vendida = bag_ventas.pluck('cantidad').sum().compute()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf4ec07",
      "metadata": {
        "id": "7cf4ec07"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, calculamos el promedio de precio unitario de todos los productos utilizando el método `pluck()` para extraer los precios unitarios y luego calculamos la media utilizando el método `mean()`. También calculamos la cantidad total de productos vendidos sumando la cantidad vendida para cada registro de venta utilizando el método `sum()`.\n",
        "\n",
        "Hemos visto cómo utilizar Dask Bags en Python para procesar conjuntos de datos no estructurados de manera eficiente. Utilizando ejemplos con datos simulados, exploramos diversas operaciones básicas, como el filtrado, la transformación y el análisis de datos, utilizando métodos como `filter()`, `map()`, `pluck()` y funciones de agregación como `count()`, `mean()` y `sum()`. Dask Bags proporciona una interfaz simple y flexible para trabajar con grandes volúmenes de datos de manera paralela y distribuida. Con los ejemplos proporcionados, esperamos haber demostrado la utilidad y la versatilidad de Dask Bags para el procesamiento de datos en Python.\n",
        "\n",
        "\n",
        "# Computación Distribuida con Dask\n",
        "\n",
        "En este apartado, exploraremos cómo utilizar Dask para realizar computación distribuida, lo que nos permitirá escalar nuestros cálculos para manejar grandes volúmenes de datos en clústeres de computadoras. Comenzaremos configurando un clúster de computación distribuida, luego discutiremos la escalabilidad y el paralelismo en Dask, y finalmente exploraremos estrategias para optimizar la ejecución distribuida con Dask.\n",
        "\n",
        "## 1. Configuración de un Clúster de Computación Distribuida\n",
        "\n",
        "Para comenzar a trabajar con Dask en un entorno distribuido, necesitamos configurar un clúster de computadoras que ejecutarán nuestras tareas. Esto puede hacerse utilizando herramientas como Kubernetes, Hadoop, o simplemente configurando un clúster de máquinas virtuales o contenedores Docker.\n",
        "\n",
        "### Ejemplo 1: Configuración de un Clúster Local con Dask.distributed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "50b6cbf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50b6cbf5",
        "outputId": "19dd9379-78db-4696-c63b-9f3fbd59e215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:46425\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:46177'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:43275'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:44705'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:41033'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:45659', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:45659\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54408\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:35179', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:35179\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54424\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:37343', name: 3, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37343\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54440\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:33773', name: 2, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:33773\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54446\n",
            "INFO:distributed.scheduler:Receive client connection: Client-63d30727-da80-11ee-808a-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:54462\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from dask.distributed import Client, LocalCluster\n",
        "\n",
        "# Configurar un clúster local con 4 trabajadores\n",
        "cluster = LocalCluster(n_workers=4)\n",
        "\n",
        "# Conectar un cliente Dask al clúster\n",
        "client = Client(cluster)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3991f42f",
      "metadata": {
        "id": "3991f42f"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos `LocalCluster` de Dask.distributed para configurar un clúster local con 4 trabajadores en nuestra máquina local. Luego, creamos un cliente Dask para conectarnos al clúster.\n",
        "\n",
        "## 2. Escalabilidad y Paralelismo en Dask\n",
        "\n",
        "Una vez que hemos configurado un clúster de computación distribuida, podemos aprovechar el escalado y el paralelismo que ofrece Dask para ejecutar tareas en paralelo en múltiples nodos del clúster.\n",
        "\n",
        "### Ejemplo 2: Escalabilidad con Dask Arrays\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "abc5d734",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abc5d734",
        "outputId": "75510941-fb03-4361-b0ec-1ee99199f4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suma total: 499996440.704679\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import dask.array as da\n",
        "\n",
        "# Crear un array Dask masivo\n",
        "datos_masivos = da.random.random(size=(1000000000,), chunks=(10000000,))\n",
        "\n",
        "# Calcular la suma de los elementos del array\n",
        "suma_total = datos_masivos.sum()\n",
        "\n",
        "# Imprimir la suma total\n",
        "print(\"Suma total:\", suma_total.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "492da887",
      "metadata": {
        "id": "492da887"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un array Dask masivo con 1,000,000,000 elementos y luego calculamos la suma total de los elementos del array. Dask distribuirá automáticamente la tarea en paralelo en los nodos del clúster para aprovechar al máximo los recursos disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d602b908",
      "metadata": {
        "id": "d602b908"
      },
      "outputs": [],
      "source": [
        "\n",
        "import dask.array as da\n",
        "\n",
        "# Crear un array Dask masivo con un tamaño de chunks optimizado\n",
        "datos_masivos_optimizados = da.random.random(size=(1000000000,), chunks=(1000000,))\n",
        "\n",
        "# Realizar operaciones en el array optimizado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c557acd1",
      "metadata": {
        "id": "c557acd1"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, ajustamos el tamaño de los chunks del array Dask para que se ajuste mejor a la memoria y el procesamiento de los nodos del clúster, lo que puede mejorar el rendimiento de las operaciones.\n",
        "\n",
        "### Ejemplo 5: Uso de Persistencia\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "45cacca4",
      "metadata": {
        "id": "45cacca4"
      },
      "outputs": [],
      "source": [
        "\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Cargar un DataFrame Dask masivo desde un archivo CSV\n",
        "df = dd.read_csv('datos_1.csv')\n",
        "\n",
        "# Persistir el DataFrame en la memoria del clúster\n",
        "df = df.persist()\n",
        "\n",
        "# Realizar operaciones en el DataFrame persistido\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125e6586",
      "metadata": {
        "id": "125e6586"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos el método `persist()` para almacenar el DataFrame en la memoria del clúster, lo que puede evitar la necesidad de volver a calcularlo en cada paso de la ejecución y mejorar el rendimiento.\n",
        "\n",
        "Hemos explorado cómo utilizar Dask para realizar computación distribuida en Python, permitiéndonos escalar nuestros cálculos para manejar grandes volúmenes de datos en clústeres de computadoras. Configuramos un clúster de computación distribuida, discutimos la escalabilidad y el paralelismo en Dask, y exploramos estrategias para optimizar la ejecución distribuida, como la optimización del tamaño de los chunks y el uso de la persistencia. Con los ejemplos proporcionados, esperamos haber demostrado la utilidad y la versatilidad de Dask para el procesamiento distribuido de datos en Python.\n",
        "\n",
        "# Integración de Dask con Otras Bibliotecas en Python\n",
        "\n",
        "En este apartado, exploraremos cómo integrar Dask con otras bibliotecas populares en Python, como NumPy, Pandas, Scikit-learn y TensorFlow. Veremos ejemplos detallados de cómo aprovechar las capacidades de Dask para mejorar el rendimiento y la escalabilidad en diferentes entornos.\n",
        "\n",
        "## 1. Uso de Dask con NumPy y Pandas\n",
        "\n",
        "Dask proporciona arreglos y marcos de datos distribuidos que son análogos a los objetos de NumPy y Pandas, lo que facilita la integración con estas bibliotecas populares.\n",
        "\n",
        "### Ejemplo 1: Uso de Dask Arrays con NumPy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "c2114d5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2114d5a",
        "outputId": "b0061d02-8eb1-43cb-9ad8-44a82b53b008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suma: 500167.35648906685\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import dask.array as da\n",
        "import numpy as np\n",
        "\n",
        "# Crear un arreglo NumPy con datos simulados\n",
        "datos_numpy = np.random.random(size=(1000000,))\n",
        "\n",
        "# Convertir el arreglo NumPy en un arreglo Dask\n",
        "array_dask = da.from_array(datos_numpy, chunks=(100000,))\n",
        "\n",
        "# Calcular la suma de los elementos del arreglo Dask\n",
        "suma = array_dask.sum()\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(\"Suma:\", suma.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa7e21aa",
      "metadata": {
        "id": "aa7e21aa"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un arreglo NumPy con datos simulados y luego lo convertimos en un arreglo Dask utilizando la función `from_array()`. Luego, realizamos una operación de suma en paralelo utilizando el método `sum()` y obtenemos el resultado con `compute()`.\n",
        "\n",
        "### Ejemplo 2: Uso de Dask DataFrames con Pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "729f2cf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "729f2cf0",
        "outputId": "2e5b2a4c-39db-4b43-f568-50a407988f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/distributed/client.py:3160: UserWarning: Sending large graph of size 13.36 MiB.\n",
            "This may cause some slowdown.\n",
            "Consider scattering data ahead of time and using futures.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media de B: 0.5002187686092892\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame Pandas con datos simulados\n",
        "datos_pandas = pd.DataFrame({\n",
        "    'A': np.random.randint(0, 100, size=1000000),\n",
        "    'B': np.random.rand(1000000),\n",
        "    'C': ['categoria_' + str(i % 10) for i in range(1000000)]\n",
        "})\n",
        "\n",
        "# Convertir el DataFrame Pandas en un DataFrame Dask\n",
        "df_dask = dd.from_pandas(datos_pandas, npartitions=4)\n",
        "\n",
        "# Filtrar los datos utilizando Dask\n",
        "df_filtrado = df_dask[df_dask['A'] > 50]\n",
        "\n",
        "# Calcular la media de la columna 'B'\n",
        "media_b = df_filtrado['B'].mean()\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(\"Media de B:\", media_b.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d6903b",
      "metadata": {
        "id": "10d6903b"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un DataFrame Pandas con datos simulados y luego lo convertimos en un DataFrame Dask utilizando la función `from_pandas()`. Luego, realizamos una operación de filtrado y cálculo de media utilizando Dask y obtenemos el resultado con `compute()`.\n",
        "\n",
        "## 2. Integración con Herramientas de Machine Learning\n",
        "\n",
        "Dask se puede integrar con herramientas de machine learning populares como Scikit-learn y TensorFlow para manejar grandes volúmenes de datos y aprovechar el paralelismo y la distribución.\n",
        "\n",
        "### Ejemplo 3: Uso de Dask con Scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dask-ml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km1G5AP22Ho5",
        "outputId": "6e65e107-628d-4d94-d3e7-16df3e8925b4"
      },
      "id": "Km1G5AP22Ho5",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dask-ml\n",
            "  Downloading dask_ml-2023.3.24-py3-none-any.whl (148 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/148.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m112.6/148.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dask[array,dataframe]>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (2023.8.1)\n",
            "Requirement already satisfied: distributed>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (2023.8.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (0.58.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.11.4)\n",
            "Collecting dask-glm>=0.2.0 (from dask-ml)\n",
            "  Downloading dask_glm-0.3.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.10/dist-packages (from dask-ml) (1.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dask-ml) (23.2)\n",
            "Requirement already satisfied: cloudpickle>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from dask-glm>=0.2.0->dask-ml) (2.2.1)\n",
            "Collecting sparse>=0.7.0 (from dask-glm>=0.2.0->dask-ml)\n",
            "  Downloading sparse-0.15.1-py2.py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (8.1.7)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (2023.6.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe]>=2.4.0->dask-ml) (7.0.1)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.1.3)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (1.0.7)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (6.3.2)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (2.0.7)\n",
            "Requirement already satisfied: zict>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed>=2.4.0->dask-ml) (3.0.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->dask-ml) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->dask-ml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->dask-ml) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask-ml) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->dask-ml) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[array,dataframe]>=2.4.0->dask-ml) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed>=2.4.0->dask-ml) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->dask-ml) (1.16.0)\n",
            "Installing collected packages: sparse, dask-glm, dask-ml\n",
            "Successfully installed dask-glm-0.3.2 dask-ml-2023.3.24 sparse-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "827cac98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "827cac98",
        "outputId": "f3b618db-8d11-4d7a-e8be-dd335eeb8497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.96163\n"
          ]
        }
      ],
      "source": [
        "from dask_ml.model_selection import train_test_split\n",
        "from dask_ml.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generar datos simulados para clasificación binaria\n",
        "X, y = make_classification(n_samples=1000000, n_features=20, n_classes=2, random_state=42)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba con Dask\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un clasificador de regresión logística con Dask\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Ajustar el modelo con los datos de entrenamiento\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Calcular la precisión del modelo con los datos de prueba\n",
        "precision = clf.score(X_test, y_test)\n",
        "\n",
        "# Imprimir la precisión del modelo\n",
        "print(\"Precisión del modelo:\", precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42d3ccbd",
      "metadata": {
        "id": "42d3ccbd"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, generamos datos simulados para clasificación binaria utilizando `make_classification()`. Luego, dividimos los datos en conjuntos de entrenamiento y prueba utilizando Dask con `train_test_split()`. Creamos un clasificador de regresión logística con Dask y lo ajustamos a los datos de entrenamiento. Finalmente, calculamos la precisión del modelo con los datos de prueba."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28bd7bc",
      "metadata": {
        "id": "d28bd7bc"
      },
      "source": [
        "## 3. Estrategias para Mejorar el Rendimiento y la Escalabilidad\n",
        "\n",
        "Al integrar Dask con otras bibliotecas, existen algunas estrategias que podemos seguir para mejorar el rendimiento y la escalabilidad en entornos complejos.\n",
        "\n",
        "### Estrategia 1: División Eficiente de Datos\n",
        "\n",
        "Al dividir los datos para el procesamiento paralelo, es importante elegir un tamaño de chunk adecuado que optimice la eficiencia del cálculo y la comunicación entre los nodos del clúster.\n",
        "\n",
        "### Estrategia 2: Aprovechar la Distribución de Cómputo\n",
        "\n",
        "Al trabajar con grandes volúmenes de datos distribuidos, es crucial distribuir la carga de trabajo de manera equitativa entre los nodos del clúster para aprovechar al máximo los recursos disponibles.\n",
        "\n",
        "### Estrategia 3: Monitoreo y Optimización del Rendimiento\n",
        "\n",
        "Es importante monitorear el rendimiento del sistema y realizar ajustes según sea necesario para optimizar el rendimiento y garantizar un procesamiento eficiente de los datos en entornos distribuidos.\n",
        "\n",
        "Hemos explorado cómo integrar Dask con otras bibliotecas populares en Python, como NumPy, Pandas, Scikit-learn y TensorFlow, para mejorar el rendimiento y la escalabilidad en diferentes entornos de procesamiento de datos. Utilizando ejemplos detallados, hemos demostrado cómo utilizar Dask en conjunción con estas bibliotecas para realizar operaciones avanzadas de análisis de datos y machine learning en conjuntos de datos masivos. Además, hemos discutido estrategias para mejorar el rendimiento y la escalabilidad al trabajar con Dask en entornos complejos. Con estas herramientas y técnicas, los usuarios pueden aprovechar al máximo las capacidades de Dask para manejar grandes volúmenes de datos de manera eficiente y escalable en aplicaciones del mundo real.\n",
        "\n",
        "# Procesamiento de Grandes Conjuntos de Datos con Dask\n",
        "\n",
        "En este apartado, exploraremos estrategias y técnicas para procesar grandes conjuntos de datos que no caben en la memoria RAM de una sola máquina utilizando Dask. Comenzaremos generando datos simulados masivos y luego aplicaremos diversas estrategias para optimizar el procesamiento de estos datos.\n",
        "\n",
        "## Generación de Datos Simulados\n",
        "\n",
        "Antes de comenzar con los ejemplos, generaremos datos simulados masivos que utilizaremos para ilustrar las estrategias de procesamiento con Dask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "87d58ee0",
      "metadata": {
        "id": "87d58ee0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import dask.array as da\n",
        "\n",
        "# Generar un array Dask con datos simulados masivos\n",
        "datos_simulados = da.random.random(size=(1000000, 1000), chunks=(100000, 1000))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02b0be44",
      "metadata": {
        "id": "02b0be44"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un array Dask con datos simulados masivos utilizando la función `random.random()`. Especificamos el tamaño del array y el tamaño de los chunks para optimizar el procesamiento paralelo.\n",
        "\n",
        "## Estrategias para Trabajar con Grandes Conjuntos de Datos\n",
        "\n",
        "### Estrategia 1: Particionamiento de Datos\n",
        "\n",
        "El partcionamiento de datos implica dividir el conjunto de datos en partes más pequeñas (chunks) que se pueden cargar y procesar de forma independiente. Esto facilita el procesamiento paralelo y reduce la carga en la memoria RAM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "de341bc8",
      "metadata": {
        "id": "de341bc8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Dividir el array Dask en chunks más pequeños\n",
        "datos_particionados = datos_simulados.rechunk(chunks=(10000, 1000))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156727d3",
      "metadata": {
        "id": "156727d3"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos el método `rechunk()` para dividir el array Dask en chunks más pequeños, lo que optimiza el procesamiento paralelo y reduce la carga en la memoria.\n",
        "\n",
        "### Estrategia 2: Carga Bajo Demanda\n",
        "\n",
        "En lugar de cargar todos los datos en la memoria RAM de una vez, podemos cargar y procesar los datos bajo demanda, es decir, solo cuando sean necesarios para realizar cálculos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f045fae4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f045fae4",
        "outputId": "313495f3-5a49-48b1-e03e-dcef518f0c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suma de las columnas: [500303.02235813 500219.8972703  500011.58133071 499677.80598425\n",
            " 500268.84409863 499501.42450582 500194.5957752  500081.20507713\n",
            " 499926.9182078  499870.96448286 500011.35291966 499852.54022413\n",
            " 499853.1492456  499993.3860648  500028.5544884  499937.68718196\n",
            " 499699.17580991 500401.07225429 499982.08257173 500031.91479593\n",
            " 499822.72650966 500472.55234695 500023.81160212 499956.49492123\n",
            " 500405.94520436 500714.69286781 500304.04860592 499391.27799452\n",
            " 500058.51912042 500048.1531287  499674.03377099 499753.60607807\n",
            " 500193.9473537  500069.48394314 499609.36774554 499933.17039973\n",
            " 500225.62688945 499850.2617479  499971.48003813 500203.83669049\n",
            " 500061.32263829 499590.02270916 500228.41415222 499993.53131384\n",
            " 499799.43608463 500022.436806   500412.35320511 500177.93448613\n",
            " 500210.04283551 499885.88401886 499523.37392133 500175.68152994\n",
            " 499523.54233194 500157.98555178 499851.19731237 500192.6197623\n",
            " 499854.4673971  500258.85511752 499384.61049713 499923.09589245\n",
            " 499910.21118108 499938.88626892 500251.11630979 499669.19089036\n",
            " 500087.33477221 499727.61523904 499883.85288185 499639.70156774\n",
            " 500129.05929028 500004.50413006 500568.44080915 499828.38212679\n",
            " 500192.63245301 500180.07055061 500119.05836179 499938.03419486\n",
            " 499588.27259468 500145.58944302 499810.14556057 499548.61206316\n",
            " 499802.38644107 500021.0569045  500319.42314823 499812.96147799\n",
            " 500084.92102053 500188.83098864 499795.7815839  500230.86000632\n",
            " 500030.26218256 500602.24152748 499862.87260486 499734.13873908\n",
            " 500323.27039572 499840.87411067 499990.55487358 500247.85927841\n",
            " 500190.75786881 499627.56313563 499696.83506582 499646.99702298\n",
            " 499957.57009239 499381.9903871  500174.42227647 500257.47054219\n",
            " 500301.88101704 499960.58334508 500360.49078753 500303.78077949\n",
            " 499791.20519512 499890.85331509 500164.55855449 499896.34757092\n",
            " 499905.97978847 499686.39344229 499977.59205488 500146.89836452\n",
            " 500415.40416348 499780.14781535 500099.93589063 500171.10095418\n",
            " 500043.04132843 500081.9637442  500145.6656923  500518.16567011\n",
            " 499728.18411597 500185.61578462 500262.98799489 499825.18441175\n",
            " 499788.89702545 500357.3726342  500278.26355841 499999.00531704\n",
            " 500314.63919331 499641.86424195 499963.11041894 500189.49335778\n",
            " 499835.60620043 499809.31902125 500101.38159246 499908.10014012\n",
            " 499898.47793782 500064.5097179  500043.60444182 500187.3061078\n",
            " 500646.23808903 500657.4522932  499822.94824596 499739.11621972\n",
            " 499740.55841397 499891.54032748 500106.99811015 499965.9800135\n",
            " 499213.3161557  500096.48685641 500227.74459135 499133.16576782\n",
            " 499897.14456442 499189.46650398 499488.850057   499680.32246299\n",
            " 499824.06610515 499836.28953908 500193.02858077 500291.0962577\n",
            " 499952.61842119 499509.54727051 500438.61734097 499894.06120114\n",
            " 499922.37716103 499547.56427513 500264.29199611 499765.36827445\n",
            " 499991.44493406 499866.01946739 499902.05818936 499908.98790798\n",
            " 500011.18308202 499251.74826811 499805.42440389 499799.49469018\n",
            " 499719.26167691 499721.50673084 500222.58887984 500159.61825318\n",
            " 500709.28430706 499691.47130928 500145.50803346 499907.88659394\n",
            " 499848.3424462  500168.81458037 500333.79831678 500111.26026276\n",
            " 500013.54567762 499628.95539581 499748.83009271 499911.78859976\n",
            " 499671.57242745 499583.6736571  499612.91245112 499849.44705919\n",
            " 500095.98531613 499693.43205075 500157.15459436 500026.2246848\n",
            " 500224.23145758 500022.98095282 499917.92412066 500012.27293947\n",
            " 500363.17103865 500116.48767723 499957.49776779 499742.58956894\n",
            " 499779.84908502 500146.34745023 499578.83478891 499996.19402709\n",
            " 500514.14054386 500708.52550049 499677.67707368 499625.99491964\n",
            " 500285.43807631 499818.2090485  501025.8540226  499717.46099864\n",
            " 499875.98880609 500346.00055895 499489.41894864 500082.70067062\n",
            " 500042.63377426 500065.68590677 499750.52013693 499903.94388178\n",
            " 499616.90632034 499821.76491757 500126.46486606 499769.59304658\n",
            " 499905.83098968 500115.82093138 500082.56529661 499970.33676375\n",
            " 499690.34695964 500072.82735886 499747.42304168 500172.08466771\n",
            " 499543.68445724 500588.87878747 500205.09202153 500204.23095988\n",
            " 500026.88571094 500253.1238764  499948.39029945 500452.07508663\n",
            " 499529.50367476 499905.35065906 499950.64264916 499930.68594385\n",
            " 499424.08141418 500149.01105464 500002.85757762 499836.27313208\n",
            " 499995.67075035 500237.28138205 499694.79325245 500821.21535153\n",
            " 500030.93578234 499700.02553667 500080.39370507 499618.1816664\n",
            " 500039.11896891 500198.21791005 499980.93604716 499310.23036557\n",
            " 499841.18000356 500073.90595737 499838.12847415 500372.247618\n",
            " 500250.12384196 500119.99417975 499727.04729524 499653.92587446\n",
            " 500229.9294055  499896.41215295 500018.59531466 500512.94111702\n",
            " 500281.65787574 500323.30569125 500374.36211694 500062.716127\n",
            " 500115.09888256 499892.15958981 499991.01561851 500245.18409341\n",
            " 499286.33656037 499953.72773592 500072.47024131 500041.11140508\n",
            " 500000.90985605 499823.4220724  500096.43967146 500226.57872415\n",
            " 499701.65973105 499836.39283166 499899.65167956 500088.2230659\n",
            " 500072.41955755 500086.52874867 499659.88029437 500144.44040565\n",
            " 499774.4732091  500114.65259892 500004.82065834 499934.04141603\n",
            " 499640.52256359 499488.28278257 500183.12334797 498807.22979936\n",
            " 500171.21920643 499683.5011686  499750.90567341 500242.7251606\n",
            " 499705.29213992 499943.87156039 500206.05684681 500198.09132269\n",
            " 500434.24385395 499935.73814411 500120.46645055 499557.31909908\n",
            " 500482.08705697 499814.68105929 500128.32553038 500392.67155435\n",
            " 499846.40440937 500103.62198884 499787.6461744  499800.51349191\n",
            " 499874.72150648 499987.97704622 499725.97203363 499791.19435819\n",
            " 500296.71481846 500722.14297115 500423.84639429 499899.96757759\n",
            " 500250.15047964 500254.96089225 500420.47965547 499970.60054158\n",
            " 499862.39153034 499430.38784159 499857.26235897 499302.0176708\n",
            " 499912.58430127 499510.40937264 499707.19701648 499566.03437898\n",
            " 499966.79311913 500565.85774978 499630.68431674 500238.2772737\n",
            " 499973.86742217 500242.68257204 500064.67741656 499787.04331183\n",
            " 499811.35134471 499971.01690034 499886.90672144 499733.19475514\n",
            " 500246.20910208 500242.22748391 499788.42890027 499940.0550054\n",
            " 500109.64224833 500512.15908634 499998.64841593 499791.12121397\n",
            " 499566.45725415 500049.95123987 500323.39163959 500146.69213697\n",
            " 499917.49254781 500306.54313892 500032.35430905 500278.28856759\n",
            " 499759.21794172 499932.27024848 500159.91723063 500113.16859064\n",
            " 500160.09196615 499909.1716809  499888.48284387 499652.75061685\n",
            " 500123.0117886  499745.24278701 499670.57280953 499852.74505258\n",
            " 500044.7078176  499510.28255713 500224.55015607 500147.5980916\n",
            " 499430.33351725 500474.18028755 499774.83519033 499803.33667632\n",
            " 499660.58432885 499843.78367603 500049.05564097 500168.55944789\n",
            " 499767.14484617 499542.23881334 500433.71996876 500066.75682865\n",
            " 500381.63348222 499903.6390906  499903.16931488 499989.67850996\n",
            " 500456.0965022  500016.82987351 500281.94753214 499950.37509882\n",
            " 499200.71046738 499980.98182494 500275.07718743 500308.60199877\n",
            " 499866.50404186 499794.9001591  500114.59456512 500083.09960481\n",
            " 499864.04245772 499950.47643137 500028.6684405  499847.43606555\n",
            " 500146.70520283 499742.17152185 500328.27616718 499749.10027519\n",
            " 499543.37542817 500227.48128583 499994.15570009 500766.88342041\n",
            " 500322.0232445  500209.24220136 499757.46665936 500252.11036868\n",
            " 500367.79596239 499421.36069471 500055.05415248 499621.53627862\n",
            " 500027.11740071 500284.40407837 499797.19755155 500036.80156263\n",
            " 500245.76410696 500218.01752868 500072.4027967  500360.33758119\n",
            " 499768.56513332 500183.10289693 500181.93152265 500033.80625267\n",
            " 499999.61771651 499459.31092215 499403.82822684 499992.43506867\n",
            " 500365.42981385 499567.44264114 499709.06613867 500388.90846991\n",
            " 500344.03054221 500346.07434775 499959.23632805 499507.47398424\n",
            " 500555.45302578 500266.63686479 499816.40308968 499939.65149963\n",
            " 500246.38670165 500171.57940075 500276.74376462 499945.8493001\n",
            " 500066.76170824 500165.03431316 500228.11421443 499908.54265933\n",
            " 500166.92285216 499860.8831235  499307.53917757 500626.49879449\n",
            " 500180.16381321 500105.84375527 500000.11303122 500339.55819543\n",
            " 499728.62262549 499757.59691663 499913.81929774 500026.65524697\n",
            " 500070.41303734 499897.74800961 500313.5063092  500264.81830109\n",
            " 500264.4085018  499837.07834144 499791.89927512 500420.15914205\n",
            " 500659.92780341 500098.52289464 500000.52449377 500057.8550146\n",
            " 500031.53158711 500751.41958815 499824.89908761 499351.77506836\n",
            " 500014.57960282 499552.61963162 499713.02356348 500142.52643354\n",
            " 500631.26862309 500073.55458323 499665.46999287 499488.11087965\n",
            " 499420.3214156  500225.76766974 500049.9729909  500403.5958772\n",
            " 500254.52140635 500253.22265707 500080.84486595 499576.12454515\n",
            " 500283.36013279 500437.07504041 500084.71746858 500088.87693625\n",
            " 500213.12062657 500002.09805466 499989.97318646 499887.04418797\n",
            " 499981.64735623 500038.78007954 499848.05889878 499555.61051108\n",
            " 500423.71501774 500422.9167387  499648.78200891 499701.92705794\n",
            " 500536.28531852 499781.65500886 499949.16656861 499349.28684924\n",
            " 500251.79151011 500369.02751258 500016.07652688 499676.74378763\n",
            " 500355.73388837 499778.14807187 499776.41583624 500214.91366205\n",
            " 500075.37501486 500474.24765207 499634.60898756 499586.83980935\n",
            " 500108.64191791 499920.26337839 500002.78462919 499822.83996445\n",
            " 500483.58011454 500145.30693326 500201.91199594 500478.63754142\n",
            " 499806.14344131 500090.80950441 500544.60899435 500325.12079567\n",
            " 499834.1961274  500043.38579698 499981.36747669 500298.45030189\n",
            " 500308.83685391 500172.89583822 500359.03554441 499802.28069825\n",
            " 500350.15056009 499621.70669414 500050.7953032  500459.33177301\n",
            " 500365.15757796 500092.7529032  499663.84539315 500186.69780796\n",
            " 499899.05428923 499804.27495166 500316.72849219 500276.04101775\n",
            " 499900.71697217 500213.68062253 500221.81240524 499669.17085714\n",
            " 500478.74550236 499893.65226334 499830.62132768 499942.89978523\n",
            " 499964.89254331 499739.51659507 499925.38798931 499896.53705128\n",
            " 499953.6079037  500114.44510715 500001.4492501  500276.08895043\n",
            " 500150.41826986 499875.37376752 499786.58001546 500372.03665048\n",
            " 499795.3333646  500304.37149738 499675.92882015 500215.75922918\n",
            " 499774.03096347 499375.64032808 500011.3741926  500218.15774212\n",
            " 500037.13423288 499759.40702739 500313.69930122 499996.56484785\n",
            " 500271.49097011 500008.63574127 500378.74335719 500364.68614455\n",
            " 500142.47791354 499893.54415355 499860.66152605 499816.01533857\n",
            " 500244.79019453 499844.8941871  500328.29709003 500077.79493526\n",
            " 500151.47619612 500664.37270447 500061.92841053 499865.5165972\n",
            " 500388.99168171 499911.66610985 499571.17589698 500506.82111835\n",
            " 500073.00869973 499878.13441084 500032.42901204 499488.70009158\n",
            " 500320.68601808 500236.24904105 499785.75380024 500010.51832751\n",
            " 499890.3110196  499881.97477362 500252.48761719 499915.36425327\n",
            " 500242.44046117 499940.16860649 500081.04321708 500138.67444632\n",
            " 500236.90716355 500256.26427782 499870.65614183 499995.58457806\n",
            " 499588.18385382 500074.84214285 499688.63310544 499966.17144236\n",
            " 499971.77387716 500296.27316229 499718.279126   499876.40104718\n",
            " 499945.93116763 499777.8599318  500616.01700981 500096.52518812\n",
            " 500100.99171359 499850.96383716 499826.28257074 499895.43500132\n",
            " 499975.49558929 499497.78760605 500090.91806942 500095.33121516\n",
            " 499886.54445139 500657.47235741 500189.28134698 500078.95877972\n",
            " 499361.45306804 499750.85760363 500226.14666251 500045.32466076\n",
            " 500032.79818153 499851.20686321 499984.16032172 499715.1568652\n",
            " 500265.17940199 499930.46008541 499506.77938706 499811.76192493\n",
            " 500041.66415892 500431.53422843 500028.68974755 500532.83933259\n",
            " 499805.26246128 499354.78982002 499714.87784942 500038.70639962\n",
            " 499956.66844967 500086.01565372 500057.14884303 499667.59891906\n",
            " 500601.49562969 500273.26951024 499742.0752491  499901.76105202\n",
            " 499819.49944243 500047.09923986 499853.67696583 499774.18674027\n",
            " 499781.57997707 500146.31723658 500211.51234562 500393.94385114\n",
            " 499844.75801846 500078.95445347 499954.99339143 500228.74391618\n",
            " 499807.44163719 499795.24374666 499906.62000314 499820.50983888\n",
            " 499668.3127662  499937.0303665  500061.55249666 499292.23114534\n",
            " 499872.61778608 499609.6368926  499956.49994879 499976.95095815\n",
            " 500372.20157095 499911.95054351 500127.96135756 499983.79376064\n",
            " 500328.6417952  500310.71228811 500350.53816891 499658.55365117\n",
            " 499934.91046251 499922.24895588 499905.29150414 500169.92846575\n",
            " 500040.98422851 499829.12914502 500284.3859168  499767.61960164\n",
            " 500106.64585366 500255.35992486 500271.8248421  500075.52218084\n",
            " 499880.1299202  500350.06482864 499942.55049938 500522.26016205\n",
            " 500212.7095553  500323.12354837 499872.68980433 499931.31033694\n",
            " 499823.07745885 500315.93728434 499973.94204716 499692.43121474\n",
            " 500454.95778258 499814.76523366 500298.41455882 500273.97059993\n",
            " 499879.88694827 500254.27070907 499918.59710886 500251.75526467\n",
            " 500135.1318175  499601.33017202 500033.65408627 499966.37228253\n",
            " 500157.29213592 500001.5694498  500290.21521505 500165.74092677\n",
            " 499854.13534967 500546.39322853 499695.51451278 499948.08504245\n",
            " 500250.1208195  499929.4907849  500263.22630706 499981.3505605\n",
            " 500360.8507305  500519.20942931 500215.6814828  499692.93919471\n",
            " 500504.4233973  500186.8442514  499595.0674474  499760.88549272\n",
            " 500059.55738997 499927.43709825 500068.91667037 499934.87957909\n",
            " 499742.26160979 500390.39031383 499964.82191807 499748.31404211\n",
            " 499663.56556085 500154.69462527 500340.73027113 499644.66457622\n",
            " 499859.10240342 500217.06433894 500049.75755344 500022.07402619\n",
            " 500035.68526665 500628.69213084 499999.99562167 500048.33911318\n",
            " 499592.46590488 500043.49390413 500039.10107023 499804.09085178\n",
            " 499847.88096168 500104.54417933 499748.63659023 500714.80284358\n",
            " 500017.90451426 500215.57187823 499819.95332769 499601.97485444\n",
            " 500085.45647184 500482.71693948 499793.65096207 499684.76627001\n",
            " 499978.5649961  500379.4628553  500209.42082114 500315.69387602\n",
            " 500083.94941391 499608.79049069 500365.82111789 500640.87249269\n",
            " 500056.55102802 500096.298663   499886.96746088 500097.78025839\n",
            " 499836.990286   500147.14980512 500552.47173757 499708.26708434\n",
            " 500234.19967058 500125.12098227 500007.43881121 499811.32379487\n",
            " 500413.33616206 499783.36989221 499653.24751322 500029.1586342\n",
            " 499998.50002608 500240.56073438 500059.96162736 500083.06461636\n",
            " 500200.03739013 500284.18131272 499803.52797433 500084.33101061\n",
            " 499848.63719126 500344.08882977 500271.30848634 499986.4592806\n",
            " 500039.47942658 499911.39563687 500317.18936368 499607.43377901\n",
            " 500120.58696804 499898.81375235 499329.3088167  499832.06257255\n",
            " 500412.23993896 500584.32096043 499946.41932076 500225.22436044\n",
            " 500132.75709622 499965.35746263 499340.11626122 500200.04969611\n",
            " 500243.58606708 499813.07920975 499783.54203176 500330.04094969\n",
            " 500454.21638637 500200.89744109 500608.21015155 499625.03279521\n",
            " 499951.92019577 499957.64115022 499988.33832122 500020.50570786\n",
            " 499773.68733881 499496.42223856 500189.47206833 499911.38516195\n",
            " 499798.64519787 499713.51007362 500015.72932293 499859.22258596\n",
            " 499969.33936042 500425.88577137 500158.29221446 500266.1007453\n",
            " 499684.06119558 499757.67245788 500524.35667518 499553.99984742\n",
            " 499937.744538   499629.57609056 500224.98062253 499730.68756968\n",
            " 499799.58547112 499611.83115891 500081.52449011 499939.10764899\n",
            " 500501.53028606 499996.23142528 499828.55184632 500019.25469485\n",
            " 500345.25302877 499654.13875243 500389.40005449 499515.34538595\n",
            " 500078.23969739 500381.17568836 500113.08762725 500907.11149398\n",
            " 500067.13664014 499907.32875971 499784.13157427 500125.71831553\n",
            " 499390.53265308 500178.26438372 499531.65812572 500617.30279906\n",
            " 500357.19352562 500043.53596508 499983.21399717 499832.30566117\n",
            " 500221.87112016 499958.2123048  499885.86032226 499874.7391553\n",
            " 500135.7656593  499763.15481519 500187.85693704 500737.12053746\n",
            " 500046.02393478 500012.24031592 500185.34842111 499833.13701171\n",
            " 499589.83198948 500239.64523351 499787.43864839 499962.16114304\n",
            " 499845.50232218 499587.86371534 500249.92937511 500435.79747188\n",
            " 499715.53296573 500188.79939793 499988.25377605 500108.53074352\n",
            " 500183.21471514 499326.50734397 500098.17414941 500153.33058562\n",
            " 499626.06456294 500140.25477062 500087.61688333 499764.3971793\n",
            " 499684.01299251 499914.19509643 500319.26936677 500397.37829826\n",
            " 499943.03371341 500073.15776265 499840.93878997 499720.5603912\n",
            " 500217.08894798 499875.46793574 500266.50993126 500587.84580584\n",
            " 499925.88070887 499503.14992815 500027.57859502 500200.8410391 ]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular la suma de las columnas bajo demanda\n",
        "suma_columnas = datos_simulados.sum(axis=0)\n",
        "\n",
        "# Imprimir la suma de las columnas\n",
        "print(\"Suma de las columnas:\", suma_columnas.compute())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "787fd555",
      "metadata": {
        "id": "787fd555"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, calculamos la suma de las columnas del array Dask bajo demanda utilizando el método `sum()` con el parámetro `axis=0`, lo que permite procesar las columnas una por una sin cargar todo el conjunto de datos en la memoria.\n",
        "\n",
        "### Estrategia 3: Optimización de Operaciones\n",
        "\n",
        "Al utilizar operaciones específicas de Dask y optimizar el uso de funciones paralelas, podemos mejorar el rendimiento del procesamiento de grandes conjuntos de datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0c875f7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c875f7d",
        "outputId": "a2f2c45c-73c4-470f-fa4a-e3643231f66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media de los datos por filas: [0.48916153 0.49834239 0.49091542 ... 0.50915176 0.5061521  0.50018872]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calcular la media de los datos por filas de manera optimizada\n",
        "media_filas = datos_simulados.mean(axis=1).compute()\n",
        "\n",
        "# Imprimir la media de los datos por filas\n",
        "print(\"Media de los datos por filas:\", media_filas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "fb0f96d0",
      "metadata": {
        "id": "fb0f96d0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import dask.array as da\n",
        "\n",
        "# Generar un array Dask con datos simulados masivos\n",
        "datos_simulados = da.random.random(size=(1000000, 1000), chunks=(100000, 1000))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5bc68cd",
      "metadata": {
        "id": "c5bc68cd"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un array Dask con datos simulados masivos utilizando la función `random.random()`. Especificamos el tamaño del array y el tamaño de los chunks para optimizar el procesamiento paralelo.\n",
        "\n",
        "## Herramientas para el Diagnóstico de Rendimiento en Dask\n",
        "\n",
        "### 1. Dashboard de Dask\n",
        "\n",
        "Dask proporciona un dashboard interactivo que permite monitorear el rendimiento de las tareas, el uso de la memoria y la distribución de la carga de trabajo en el clúster.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "0250c857",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "0250c857",
        "outputId": "0fd485fc-588e-43a6-fcb2-a5a3fcb0cccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
            "Perhaps you already have a cluster running?\n",
            "Hosting the HTTP server on port 35121 instead\n",
            "  warnings.warn(\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:45299\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:35121/status\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:34361'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:46505'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:33801', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:33801\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:60784\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:33411', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:33411\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:60794\n",
            "INFO:distributed.scheduler:Receive client connection: Client-37274cd1-da81-11ee-808a-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:60796\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://127.0.0.1:35121/status'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "\n",
        "from dask.distributed import Client\n",
        "\n",
        "# Iniciar un cliente Dask para acceder al dashboard\n",
        "cliente = Client()\n",
        "\n",
        "# Abrir el dashboard en el navegador\n",
        "cliente.dashboard_link\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c57876b2",
      "metadata": {
        "id": "c57876b2"
      },
      "source": [
        "\n",
        "\n",
        "Al ejecutar este código, se abrirá automáticamente el dashboard de Dask en el navegador, donde se puede monitorear el rendimiento de las tareas y el estado del clúster en tiempo real.\n",
        "\n",
        "### 2. Profiling con `dask.diagnostics`\n",
        "\n",
        "La biblioteca `dask.diagnostics` proporciona herramientas para perfilar y diagnosticar el rendimiento de las operaciones Dask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "411804cb",
      "metadata": {
        "id": "411804cb"
      },
      "outputs": [],
      "source": [
        "import dask.array as da\n",
        "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
        "\n",
        "# Definir una operación de Dask (en este caso, una suma de dos matrices)\n",
        "a = da.random.random((1000, 1000), chunks=(100, 100))\n",
        "b = da.random.random((1000, 1000), chunks=(100, 100))\n",
        "mi_operacion_dask = (a + b).sum()\n",
        "\n",
        "# Ejecutar un perfil para monitorear el rendimiento\n",
        "with Profiler() as prof, ResourceProfiler(dt=0.25) as rprof, CacheProfiler() as cprof:\n",
        "    # Ejecutar y perfilar la operación de Dask\n",
        "    resultado = mi_operacion_dask.compute()\n",
        "\n",
        "# Obtener estadísticas de rendimiento\n",
        "prof_results = prof.results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72cde760",
      "metadata": {
        "id": "72cde760"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos el `Profiler` para monitorear el rendimiento de una operación Dask. Luego, podemos acceder a las estadísticas de rendimiento a través del objeto `stats`.\n",
        "\n",
        "## Identificación y Resolución de Cuellos de Botella\n",
        "\n",
        "### 1. Uso de Dashboard para Identificar Cuellos de Botella\n",
        "\n",
        "El dashboard de Dask proporciona información detallada sobre el rendimiento de las tareas, lo que facilita la identificación de cuellos de botella en el procesamiento.\n",
        "\n",
        "Por ejemplo, si se observa un alto tiempo de ejecución en una tarea específica, puede ser un indicio de un cuello de botella en esa operación. Se puede analizar la tarea en detalle para identificar posibles mejoras en el rendimiento.\n",
        "\n",
        "### 2. Uso de Profiling para Identificar Cuellos de Botella\n",
        "\n",
        "El profiling con `dask.diagnostics` permite identificar áreas de código que consumen más recursos o tienen un rendimiento deficiente.\n",
        "\n",
        "Por ejemplo, al analizar los resultados del perfil, podemos identificar las operaciones que consumen más memoria o tienen un alto tiempo de ejecución. Luego, podemos optimizar esas operaciones utilizando técnicas como el particionamiento de datos o la optimización de algoritmos.\n",
        "\n",
        "## Mejores Prácticas para Optimizar el Rendimiento de Aplicaciones Dask\n",
        "\n",
        "### 1. Particionamiento de Datos\n",
        "\n",
        "El particionamiento de datos implica dividir el conjunto de datos en partes más pequeñas (chunks) que se pueden cargar y procesar de forma independiente. Esto facilita el procesamiento paralelo y reduce la carga en la memoria RAM.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "6d4b4686",
      "metadata": {
        "id": "6d4b4686"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Dividir el array Dask en chunks más pequeños\n",
        "datos_particionados = datos_simulados.rechunk(chunks=(10000, 1000))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7321344",
      "metadata": {
        "id": "b7321344"
      },
      "source": [
        "\n",
        "\n",
        "### 2. Uso de Operaciones Paralelas\n",
        "\n",
        "Dask aprovecha el paralelismo para realizar operaciones en datos distribuidos de manera eficiente. Utilizar operaciones paralelas siempre que sea posible puede mejorar significativamente el rendimiento de las aplicaciones Dask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "03669ae2",
      "metadata": {
        "id": "03669ae2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ejemplo de operación paralela\n",
        "resultado = datos_simulados.sum(axis=0).compute()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9c7e222",
      "metadata": {
        "id": "f9c7e222"
      },
      "source": [
        "\n",
        "\n",
        "### 3. Ajuste de Configuraciones\n",
        "\n",
        "Es posible ajustar varias configuraciones en Dask para optimizar el rendimiento, como el tamaño de los chunks, el número de workers y la configuración de memoria.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "d7ee1e60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7ee1e60",
        "outputId": "d5375e68-e69e-455f-bbdc-9a10a581d8e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
            "Perhaps you already have a cluster running?\n",
            "Hosting the HTTP server on port 45183 instead\n",
            "  warnings.warn(\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:35693\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:45183/status\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:38257'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:39745'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:36009'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:41879'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:32775', name: 3, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:32775\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:37230\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:39695', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:39695\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:37232\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:45179', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:45179\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:37238\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:38193', name: 2, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:38193\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:37242\n",
            "INFO:distributed.scheduler:Receive client connection: Client-934b6b5f-da81-11ee-808a-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:37244\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from dask.distributed import Client, LocalCluster\n",
        "\n",
        "# Configurar un clúster local con un número específico de workers\n",
        "cluster = LocalCluster(n_workers=4)\n",
        "cliente = Client(cluster)\n",
        "\n",
        "# Ajustar el tamaño de los chunks\n",
        "datos_simulados = datos_simulados.rechunk(chunks=(10000, 1000))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a02c250",
      "metadata": {
        "id": "5a02c250"
      },
      "source": [
        "\n",
        "\n",
        "El diagnóstico y la optimización del rendimiento son aspectos críticos al trabajar con Dask para procesar grandes conjuntos de datos. Herramientas como el dashboard de Dask y `dask.diagnostics` facilitan la identificación de cuellos de botella y la optimización del rendimiento. Además, seguir mejores prácticas como el particionamiento de datos, el uso de operaciones paralelas y el ajuste de configuraciones puede mejorar significativamente el rendimiento de las aplicaciones Dask. Con estas herramientas y técnicas, los usuarios pueden maximizar el rendimiento y la eficiencia al trabajar con grandes volúmenes de datos en entornos distribuidos con Dask.\n",
        "\n",
        "# Uso de Map-Reduce y Paralelismo en Dask\n",
        "\n",
        "En este apartado, exploraremos cómo utilizar map-reduce y otras técnicas de paralelismo en Dask para procesar grandes volúmenes de datos de manera eficiente. Comenzaremos generando datos simulados masivos y luego aplicaremos diversas estrategias de paralelismo con Dask.\n",
        "\n",
        "## Generación de Datos Simulados\n",
        "\n",
        "Antes de comenzar con los ejemplos, generaremos datos simulados masivos que utilizaremos para ilustrar las técnicas de paralelismo con Dask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "fef7291f",
      "metadata": {
        "id": "fef7291f"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import dask.array as da\n",
        "\n",
        "# Generar un array Dask con datos simulados masivos\n",
        "datos_simulados = da.random.random(size=(1000000, 1000), chunks=(100000, 1000))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "866ea65f",
      "metadata": {
        "id": "866ea65f"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, creamos un array Dask con datos simulados masivos utilizando la función `random.random()`. Especificamos el tamaño del array y el tamaño de los chunks para optimizar el procesamiento paralelo.\n",
        "\n",
        "## Map-Reduce con Dask\n",
        "\n",
        "El patrón map-reduce es una técnica poderosa para procesar grandes volúmenes de datos de manera distribuida y paralela. Dask proporciona herramientas para implementar este patrón de manera eficiente.\n",
        "\n",
        "### Ejemplo 1: Calcular la Suma de Elementos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "4340de14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4340de14",
        "outputId": "19bd097f-1958-4530-867e-41d8ce697723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de suma_chunk: (1000000, 1000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.nanny:Worker process 2843 was killed by signal 9\n",
            "INFO:distributed.core:Connection to tcp://127.0.0.1:37230 has been closed.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:32775', name: 3, status: running, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1709596217.0714898')\n",
            "WARNING:distributed.nanny:Restarting worker\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:44311', name: 3, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:44311\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:48296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suma Total: 500010818.670537\n"
          ]
        }
      ],
      "source": [
        "import dask.array as da\n",
        "import numpy as np\n",
        "\n",
        "# Aplicar la función map para calcular la suma de cada chunk\n",
        "suma_chunk = datos_simulados.map_blocks(lambda x: np.sum(x, axis=1))\n",
        "\n",
        "# Verificar las dimensiones del array resultante\n",
        "print(\"Dimensiones de suma_chunk:\", suma_chunk.shape)\n",
        "\n",
        "# Calcular la suma total sumando a lo largo del eje 0\n",
        "suma_total = da.sum(suma_chunk, axis=0)\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(\"Suma Total:\", suma_total.compute())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cb57aca",
      "metadata": {
        "id": "8cb57aca"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos la función `map_blocks()` para aplicar la función de suma a cada chunk de datos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca3d36be",
      "metadata": {
        "id": "ca3d36be"
      },
      "source": [
        "## Implementación de Algoritmos Paralelos Avanzados\n",
        "\n",
        "Dask es una herramienta versátil que permite implementar una amplia gama de algoritmos paralelos avanzados para el procesamiento de datos.\n",
        "\n",
        "### Ejemplo 4: Algoritmo de Clasificación Paralela\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "cacfd7fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cacfd7fd",
        "outputId": "6aef1d4b-d4e8-4318-d2e7-fb78525f61e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
            "Perhaps you already have a cluster running?\n",
            "Hosting the HTTP server on port 44609 instead\n",
            "  warnings.warn(\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:43141\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:44609/status\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:45951'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:46117'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:42453', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:42453\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:45962\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:37815', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37815\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:45950\n",
            "INFO:distributed.scheduler:Receive client connection: Client-bf85a862-da81-11ee-808a-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:45974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 0.96163\n"
          ]
        }
      ],
      "source": [
        "from dask.distributed import Client\n",
        "from sklearn.datasets import make_classification\n",
        "from dask_ml.linear_model import LogisticRegression\n",
        "from dask_ml.model_selection import train_test_split\n",
        "\n",
        "# Crear un cliente Dask para distribuir el procesamiento\n",
        "client = Client()\n",
        "\n",
        "# Generar datos simulados para clasificación binaria\n",
        "X, y = make_classification(n_samples=1000000, n_features=20, n_classes=2, random_state=42)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba con Dask\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un clasificador de regresión logística con Dask\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Ajustar el modelo con los datos de entrenamiento\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Calcular la precisión del modelo con los datos de prueba\n",
        "precision = clf.score(X_test, y_test)\n",
        "\n",
        "# Imprimir la precisión del modelo\n",
        "print(\"Precisión del modelo:\", precision)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52511435",
      "metadata": {
        "id": "52511435"
      },
      "source": [
        "\n",
        "\n",
        "En este ejemplo, utilizamos Dask para distribuir el entrenamiento de un modelo de regresión logística en conjuntos de datos masivos. Utilizamos la biblioteca Dask-ML para realizar el entrenamiento distribuido y luego evaluamos la precisión del modelo en datos de prueba.\n",
        "\n",
        "Hemos explorado cómo utilizar map-reduce y otras técnicas de paralelismo en Dask para procesar grandes volúmenes de datos de manera eficiente. A través de ejemplos prácticos, hemos demostrado cómo implementar map-reduce con Dask para realizar operaciones distribuidas en conjuntos de datos masivos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}